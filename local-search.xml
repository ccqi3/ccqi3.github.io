<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>zookeeper-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/</url>
    
    <content type="html"><![CDATA[<h2 id="zookeeper环境搭建"><a href="#zookeeper环境搭建" class="headerlink" title="zookeeper环境搭建"></a>zookeeper环境搭建</h2><p>新建文件docker-compose-zk.yml</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs"><span class="hljs-attribute">version</span>: &#x27;3.1&#x27;<br><br><span class="hljs-attribute">services:</span><br>  zoo1:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo1<br>    ports:<br>      - 2181:2181<br>    environment:<br>      ZOO_MY_ID: 1<br>      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo2:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo2<br>    ports:<br>      - 2182:2181<br>    environment:<br>      ZOO_MY_ID: 2<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo3:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo3<br>    ports:<br>      - 2183:2181<br>    environment:<br>      ZOO_MY_ID: 3<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181<br></code></pre></td></tr></table></figure><p>在目录下执行<code>docker-compose -f docker-compose-zk.yml up -d</code></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>rocketMQ-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/</url>
    
    <content type="html"><![CDATA[<h2 id="rocketMQ环境搭建"><a href="#rocketMQ环境搭建" class="headerlink" title="rocketMQ环境搭建"></a>rocketMQ环境搭建</h2><p><code>git clone https://github.com/foxiswho/docker-rocketmq.git</code></p><p>切换分支<code>git checkout v4.4.0</code></p><p>该项目目录结构为</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">docker-rocketmq</span>/<br>├── <span class="hljs-selector-tag">base</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│   └── <span class="hljs-selector-tag">scripts</span><br>│       ├── <span class="hljs-selector-tag">runbroker-customize</span><span class="hljs-selector-class">.sh</span><br>│       ├── <span class="hljs-selector-tag">runserver-customize</span><span class="hljs-selector-class">.sh</span><br>│       └── <span class="hljs-selector-tag">to_bytes</span><span class="hljs-selector-class">.gawk</span><br>├── <span class="hljs-selector-tag">broker</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">README</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">rmq</span>   #进入此目录<br>│   ├── <span class="hljs-selector-tag">docker-compose</span><span class="hljs-selector-class">.yml</span><br>│   └── <span class="hljs-selector-tag">rmq</span><br>│       ├── <span class="hljs-selector-tag">brokerconf</span><br>│       │   └── <span class="hljs-selector-tag">broker</span><span class="hljs-selector-class">.conf</span><br>│       ├── <span class="hljs-selector-tag">logs</span><br>│       ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│       └── <span class="hljs-selector-tag">store</span><br>└── <span class="hljs-selector-tag">server</span><br>    ├── <span class="hljs-selector-tag">Dockerfile</span><br>    └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br></code></pre></td></tr></table></figure><p>进入rmq目录下，执行<code>docker-compose up</code> 即可。</p><p>启动IP,如果 docker 报 <code>com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed</code>修改<br><code>broker.conf</code> 文件里brokerIP1设置为宿主ip即可</p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>elastic-search-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/</url>
    
    <content type="html"><![CDATA[<h2 id="elastic-search环境搭建"><a href="#elastic-search环境搭建" class="headerlink" title="elastic-search环境搭建"></a>elastic-search环境搭建</h2><p>创建目录结构为</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">docker</span>-es/<br>├── docker-compose.yaml<br>├── master<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>├── node1<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>└── node2<br>    ├── conf<br>    │   └── elasticsearch.yml<br>    ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>    └── logs<br></code></pre></td></tr></table></figure><p><code>docker-compose.yaml</code> 文件内容：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs awk">version: <span class="hljs-string">&#x27;3&#x27;</span><br>services:<br>     es-master:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-master<br>       restart: always<br>       volumes:<br>         - .<span class="hljs-regexp">/master/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/master/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/master/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>       ports:<br>         - <span class="hljs-string">&quot;9200:9200&quot;</span><br>         - <span class="hljs-string">&quot;9300:9300&quot;</span><br>       environment:<br>         - <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;</span><br>                 <br>     es-node1:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node1<br>       <span class="hljs-comment">#restart: always</span><br>       volumes:<br>         - .<span class="hljs-regexp">/node1/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/node1/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/node1/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-node2:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node2<br>       restart: always<br>       volumes:<br>        - .<span class="hljs-regexp">/node2/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>        - .<span class="hljs-regexp">/node2/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>        - .<span class="hljs-regexp">/node2/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-head:<br>       image: tobias74/elasticsearch-head:<span class="hljs-number">6</span><br>       container_name: es-head<br>       restart: always<br>       ports:<br>       - <span class="hljs-string">&quot;9100:9100&quot;</span><br></code></pre></td></tr></table></figure><p><code>master/conf/elasticsearch.yml</code> 文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">bootstrap.memory_lock:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">cluster.name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br><span class="hljs-attr">node.name:</span> <span class="hljs-string">&quot;es-master&quot;</span><br><span class="hljs-attr">node.master:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">network.host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">http.port:</span> <span class="hljs-number">9200</span><br><span class="hljs-attr">transport.tcp.port:</span> <span class="hljs-number">9300</span><br><span class="hljs-attr">discovery.seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>]<br><span class="hljs-attr">discovery.zen.minimum_master_nodes:</span> <span class="hljs-number">1</span><br><span class="hljs-attr">cluster.initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br><br><span class="hljs-attr">http.cors.enabled:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">http.cors.allow-origin:</span> <span class="hljs-string">&quot;*&quot;</span><br><span class="hljs-attr">xpack.security.audit.enabled:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p><code>node1/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node1&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9201</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9301</span><br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br><br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br><br>http.cors.<span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br>http.cors.allow-<span class="hljs-attr">origin:</span> <span class="hljs-string">&quot;*&quot;</span><br></code></pre></td></tr></table></figure><p><code>node2/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node2&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9202</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9302</span><br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br></code></pre></td></tr></table></figure><p><code>docker-compose up</code> 启动即可</p><h2 id="启动错误解决"><a href="#启动错误解决" class="headerlink" title="启动错误解决"></a>启动错误解决</h2><ol><li>docker以挂载配置文件启动elasticsearch的时候会报错误，所以需要给予文件夹权限<br>赋权命令：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">chmod <span class="hljs-number">777</span> master<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node1<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node2<span class="hljs-regexp">/data/</span><br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-run</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/</url>
    
    <content type="html"><![CDATA[<h2 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h2><p>安装命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">streamsets</span><br><span class="hljs-attribute">docker</span> run --restart <span class="hljs-literal">on</span>-failure -p <span class="hljs-number">18630</span>:<span class="hljs-number">18630</span> -d --name sdc streamsets/datacollector<br><br><span class="hljs-attribute">pgsql</span><br><span class="hljs-attribute">docker</span> run --name postgres -e POSTGRES_PASSWORD=postgres<span class="hljs-number">369</span> -p <span class="hljs-number">5432</span>:<span class="hljs-number">5432</span> -d postgres:<span class="hljs-number">9</span>.<span class="hljs-number">5</span>.<span class="hljs-number">24</span>-alpine<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-centos7</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装docker"><a href="#centos7安装docker" class="headerlink" title="centos7安装docker"></a>centos7安装docker</h2><p>安装命令：<br><code>yum install -y docker </code></p><p>启动docker<br><code>systemctl start docker</code></p><p>设置docker开机启动<br><code>systemctl enable docker</code></p><p>##安装docker-compose</p><ol><li><p>添加EPEL源</p><p> <code>yum install -y epel-release</code></p></li><li><p>安装python-pip</p><p> <code>yum install -y python-pip</code></p></li><li><p>安装docker-compose</p><p> <code>pip install docker-compose</code></p></li></ol><p>##更换镜像源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs awk">打开文件（没有就新建）<br>vim <span class="hljs-regexp">/etc/</span>docker/daemon.json<br><br>&#123;<br><span class="hljs-string">&quot;registry-mirrors&quot;</span>: [<span class="hljs-string">&quot;http://hub-mirror.c.163.com&quot;</span>]<br>&#125;<br>保存后重启即可<br>service docker restart<br><br>Docker中国区官方镜像<br>https:<span class="hljs-regexp">//</span>registry.docker-cn.com<br><br>网易<br>http:<span class="hljs-regexp">//</span>hub-mirror.c.<span class="hljs-number">163</span>.com<br><br>ustc <br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>中国科技大学<br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>阿里云容器服务(需要先创建容器镜像)<br>https:<span class="hljs-regexp">//</span>cr.console.aliyun.com/<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux常见问题</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<ol><li><p><code>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</code></p><p>解决：<code>sysctl -w vm.max_map_count=262144</code></p><p>重启虚拟机将失效<br>在<code>/etc/sysctl.conf</code>文件最后添加一行<br><code>vm.max_map_count=262144</code>即可永久修改</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>centos7安装MySQL</title>
    <link href="/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/"/>
    <url>/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装MySQL"><a href="#centos7安装MySQL" class="headerlink" title="centos7安装MySQL"></a>centos7安装MySQL</h2><ol><li><p>配置YUM源</p><p> <code>wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum localinstall mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum repolist enabled | grep &quot;mysql.*-community.*&quot;</code></p><p> 可以修改<code>vim /etc/yum.repos.d/mysql-community.repo</code>源，改变默认安装的mysql版本。比如要安装5.6版本，将5.7源的enabled=1改成enabled=0。然后再将5.6源的enabled=0改成enabled=1即可。</p></li><li><p>安装MySQL</p><p> <code>yum install mysql-community-server</code></p></li><li><p>启动MySQL服务</p><p> <code>service mysqld start</code></p></li><li><p>开机启动</p><p> <code>systemctl enable mysqld</code></p><p> <code>systemctl daemon-reload</code></p></li><li><p>修改root本地登录密码</p><p> <code>grep &#39;temporary password&#39; /var/log/mysqld.log   ---AkY&gt;ts#9)Dcv</code></p><p> <code>mysql -uroot -p</code></p><p> <code>ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;a1b2c3d4&#39;; </code></p><p> 修改密码策略</p><p> 在<code>/etc/my.cnf</code>文件添加validate_password_policy配置，指定密码策略<br>选择0（LOW），1（MEDIUM），2（STRONG）其中一种，选择2需要提供密码字典文件<br>validate_password_policy=0</p><p> 如果不需要密码策略，添加my.cnf文件中添加如下配置禁用即可：<br><code>validate_password = off</code></p></li><li><p>添加远程登录用户</p><p> 默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户：<br> mysql&gt; <code>GRANT ALL PRIVILEGES ON *.* TO &#39;mysql&#39;@&#39;%&#39; IDENTIFIED BY &#39;mysql123&#39; WITH GRANT OPTION;</code></p><p> 设置root用户远程登录</p><pre><code> use mysql; update user set host = &#39;%&#39; where user = &#39;root&#39;; FLUSH PRIVILEGES;</code></pre></li><li><p>配置默认编码为utf8</p><p> 修改<code>/etc/my.cnf</code>配置文件，在[mysqld]下添加编码配置，如下所示：</p><p> [mysqld]</p><p> character_set_server=utf8</p><p> init_connect=’SET NAMES utf8’</p></li><li><p>不区分大小写</p><p> 在<code>[mysqld]</code>下加上<code>lower_case_table_names=1</code></p></li><li><p>mysql重启服务</p><p> <code>service mysqld restart</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于gitee+hexo搭建个人博客</title>
    <link href="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/"/>
    <url>/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/</url>
    
    <content type="html"><![CDATA[<p>什么是 Hexo？</p><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。  —来自hexo官网<br><code>https://hexo.io/zh-cn/docs/</code></p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>nodejs</li><li>git</li></ul><ol><li><p>安装hexo。 （npm默认镜像源在国外，会有下载失败情况，建议更换taobao镜像源）</p><p> <code>$ npm install -g hexo-cli</code></p></li><li><p>新建个人文件夹，初始化目录为hexo目录。命令如下：</p><pre><code> $ hexo init $ npm install 执行完毕后目录如下： hexo  ├── _config.landscape.yml ├── _config.yml ├── node_modules ├── package-lock.json ├── package.json ├── scaffolds ├── source └── themes</code></pre></li><li><p>启动hexo</p></li></ol><p>在hexo目录下执行 <code>hexo server</code></p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/hexo%E5%90%AF%E5%8A%A8%E5%9B%BE.png" class><p>浏览器访问<strong><a href="http://localhost:4000/">http://localhost:4000</a></strong> 即可</p><h2 id="gitee网站配置"><a href="#gitee网站配置" class="headerlink" title="gitee网站配置"></a>gitee网站配置</h2><ol><li><p>在gitee新建仓库*<strong>.gitee.io</strong> (*号为任意名称)</p></li><li><p>修改<code>_config.yml</code>文件</p><pre><code> 这里只截取部分配置信息 # URL ## If your site is put in a subdirectory, set url as &#39;http://example.com/child&#39; and root as &#39;/child/&#39; url: 后续需要修改  root: 同目录名  deploy:   type: &#39;git&#39;   repo: git仓库地址   如： https://gitee.com/test/test   branch: master   message: blog update</code></pre></li><li><p>安装插件 <code>npm install --save hexo-deployer-git</code></p></li><li><p>执行命令<code>hexo g -d</code> 这里会提示用户名密码，成功后在gitee页面可以看到本地代码已提交到仓库中。</p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/gitee-pages.png" class></li><li><p>如图操作后点击启动，成功后复制网站地址，访问发现静态资源没有加载。</p></li></ol><ul><li>将配置文件中的url修改为网站地址 例如： <a href="http://ccqi3.gitee.io/test">http://ccqi3.gitee.io/test</a></li><li>root 后是仓库名称如 root: /test/</li></ul><ol start="6"><li>修改完后在hexo目录下再次执行<code>hexo g -d</code> (以后配置有调整或者发布新的文章都用此命令即可)</li><li>在gitee的pages页面里点击更新，再次访问网址发现已经搭建好博客了。</li></ol><h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><ul><li>修改<code>_config.yml</code> 文件中的 <code>post_asset_folder:false</code> 改为 <strong>true</strong><br>这样新建文档时会在文档同级生成同名文件夹，图片资源放入其中。</li><li>安装插件<br><code>npm install https://github.com/7ym0n/hexo-asset-image --save</code></li></ul><p><code>&#123;% asset_img test.jpg This is an test image %&#125;</code><br>test.jpg 就是图片文件名称 后面文字是图片描述</p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p><code>hexo generate</code></p><p><code>hexo server</code></p><p><code>hexo deploy</code></p><p><code>hexo clean</code></p><p><code>hexo new page &quot;type&quot; </code> <strong>type</strong> 如下：</p><table><thead><tr><th>page</th><th>type</th><th>内容</th></tr></thead><tbody><tr><td>tages</td><td>tages</td><td>标签</td></tr><tr><td>categories</td><td>categories</td><td>分类</td></tr><tr><td>archives</td><td>archives</td><td>博客</td></tr><tr><td>about</td><td>about</td><td>关于</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的博客</title>
    <link href="/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    <url>/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="为什么要写博客"><a href="#为什么要写博客" class="headerlink" title="为什么要写博客"></a>为什么要写博客</h2><ul><li>生活记录</li><li>编程笔记</li></ul>]]></content>
    
    
    <categories>
      
      <category>个人计划</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-04 yarn</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/</url>
    
    <content type="html"><![CDATA[<h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><h3 id="旧的MapReduce的架构："><a href="#旧的MapReduce的架构：" class="headerlink" title="旧的MapReduce的架构："></a>旧的MapReduce的架构：</h3><ul><li><p>JobTracker：负责资源管理，跟踪资源消耗和可用性，作业生命周期管理（调度作业任务，跟踪进度，为任务提供容错）</p></li><li><p>TaskTracker：加载或关闭任务，定时报告任务状态。</p></li><li><p>此架构会有以下问题：</p><ol><li>JobTracker是MapReduce的集中处理点，存在单点故障。</li><li>JobTracker完成了太多的任务，造成了过多的资源消耗，当MapReduce Job非常多的时候，会造成很大的内存开销。这也是业界普遍总结出老版本Hadoop的MapReduce只能支持4000节点的主机上限。</li><li>在TaskTracker端，以map/reduce task的数目作为资源的表示过于简单，没有考虑到cpu/内存的占用情况，如果两个大内存消耗的task被调度的一起，很容易出现OOM。</li><li>在TaskTracker端，把资源强制划分为map task slot 和 reduce task slot，如果当系统中只有map task或者只有reduce task的时候，会造成资源浪费，也就是集群资源的利用问题。</li><li>总结就是单点问题和资源利用率问题。</li></ol></li></ul><hr><h3 id="yarn的架构："><a href="#yarn的架构：" class="headerlink" title="yarn的架构："></a>yarn的架构：</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" class title="yarn架构图"><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E6%9E%B6%E6%9E%84%E5%9B%BE2.jpg" class title="yarn架构图"><p>YARN就是把JobTracker的职责拆分，将资源管理和任务调度监控拆分成独立的进程，一个全局的资源管理和一个每个作业的管理（ApplicationMaster）ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行。</p><ul><li>ResourceManager : RM  – 全局资源管理和任务调度<ul><li>整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度。</li><li>处理客户端的请求：提交一个作业，杀死一个作业</li><li>监控NM，一旦NM挂了，那么改NM上运行的任务需要告诉AM来如何进行处理</li></ul></li><li>NodeManager: NM – 单个节点的资源管理和监控<ul><li>整个集群中有多个，负责自己本身节点资源管理和使用</li><li>定时向RM汇报本节点的资源使用情况</li><li>接受并处理来自RM的各种命令：启动Container</li><li>处理来自AM的命令</li><li>每个节点的资源管理</li></ul></li><li>ApplicationMaster: AM – 单个作业的资源管理和任务监控<ul><li>每个应用程序对应一个：MR、Spark，负责应用程序的管理</li><li>为应用程序向RM申请资源（core、memory），分配给内部task</li><li>需要与NM通信： 启动/停止task，task是运行在container里面，AM也是运行在Container里面的</li></ul></li><li>Container  – 资源申请的单位和任务运行的容器<ul><li>封装了CPU、Memory等资源的一个容器</li><li>是一个任务运行环境的抽象</li></ul></li><li>Client<ul><li>提交作业</li><li>查询作业的运行进度</li><li>杀死作业</li></ul></li></ul><hr><h3 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94.jpg" class title="架构对比"><h2 id="YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。"><a href="#YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。" class="headerlink" title="YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。"></a><strong>YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。</strong></h2><h3 id="YARN的基本流程"><a href="#YARN的基本流程" class="headerlink" title="YARN的基本流程"></a>YARN的基本流程</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B2.jpg" class title="架构对比"><ol><li>Job submission<ol><li> 从ResourceManager中获取一个Application ID检查作业输出配置，计算输入分片拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行。</li></ol></li><li>Job initialization<ol><li> ResourceManager将作业递交给Scheduler（有很多算法，一般根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process 并交给NodeManager。</li><li>管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的调度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master ，还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行。</li></ol></li><li>Task assignment<ol><li>ApplicationMaster 向Resource Manager 申请资源（一个个的Container，指定任务分配资源要求）一般是根据data locality来分配资源。</li></ol></li><li>Task execution<ol><li>ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container从HDFS中读取任务所需资源（job  jar ，配置文件等）然后执行该任务。</li></ol></li><li>Progress and status update<ol><li>定时将任务的进度和状态报告给ApplicationMaster Client 定时向ApplicationMaster获取整个任务的进度和状态。</li></ol></li><li>Job completion<ol><li>Client 定时检查整个作业是否完成，作业完成后，会清空临时文件，目录。</li></ol></li></ol><hr><h3 id="YARN-ResourceManager"><a href="#YARN-ResourceManager" class="headerlink" title="YARN - ResourceManager"></a>YARN - ResourceManager</h3><p><strong>负责全局的资源管理和任务调度，把整个集群当成计算资源池，只关注分配，不管应用，且不负责容错。</strong></p><h4 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h4><ol><li>以前资源是每个节点分成一个个的Map slot和Reduce slot，现在是一个个Container，每个Container可以根据需要运行ApplicationMaster、map、Reduce或任意的程序。</li><li>以前的资源分配是静态的，目前是动态的，资源利用率更高。</li><li>Container是资源申请的单位，一个资源申请格式：<code>&lt;resource-name, priority, resource-requirement, number-of-containers&gt;</code>, resource-name：主机名、机架名或*（代表任意机器）, resource-requirement：目前只支持CPU和内存</li><li>用户提交作业到ResourceManger ，然后在某个NodeManager上分配一个Container来运行ApplicationMaster，ApplicationMaster再根据自身程序需要向ResourceManager申请资源。</li><li>YARN有一套Container的生命周期管理机制，而ApplicationMaster和其Container之间的管理是应用程序自己定义的。</li></ol><h4 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h4><ol><li>只关注资源的使用情况，根据需求合理分配资源。</li><li>Schedule可以根据申请的需要，在特定的机器上申请特定的资源（ApplicationMaster负责申请资源时的数据本地化的考虑，ResourceManager将尽量满足其申请需求，在指定的机器上分配Container，从而减少数据移动）。<h4 id="内部结构"><a href="#内部结构" class="headerlink" title="内部结构"></a>内部结构</h4><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/ResourceManager.jpg" class></li></ol><ul><li>Client Service: 应用提交、终止、输出信息（应用、队列、集群等的状态信息）。</li><li>Adaminstration Service: 队列、节点、Client权限管理。</li><li>ApplicationMasterService: 注册、终止ApplicationMaster, 获取ApplicationMaster的资源申请或取消的请求，并将其异步地传给Scheduler, 单线程处理。</li><li>ApplicationMaster Liveliness Monitor: 接收ApplicationMaster的心跳消息，如果某个ApplicationMaster在一定时间内没有发送心跳，则被任务失效，其资源将会被回收，然后ResourceManager会重新分配一个ApplicationMaster运行该应用（默认尝试2次）。</li><li>Resource Tracker Service: 注册节点, 接收各注册节点的心跳消息。</li><li>NodeManagers Liveliness Monitor: 监控每个节点的心跳消息，如果长时间没有收到心跳消息，则认为该节点无效, 同时所有在该节点上的Container都标记成无效，也不会调度任务到该节点运行。</li><li>ApplicationManager: 管理应用程序，记录和管理已完成的应用。</li><li>ApplicationMaster Launcher: 一个应用提交后，负责与NodeManager交互，分配Container并加载ApplicationMaster，也负责终止或销毁。</li><li>YarnScheduler: 资源调度分配， 有FIFO(with Priority)，Fair，Capacity方式。</li><li>ContainerAllocationExpirer: 管理已分配但没有启用的Container，超过一定时间则将其回收。</li></ul><hr><h3 id="YARN-NodeManager"><a href="#YARN-NodeManager" class="headerlink" title="YARN - NodeManager"></a>YARN - NodeManager</h3><p>Node节点下的Container管理</p><ol><li>启动时向ResourceManager注册并定时发送心跳信息，等待ResourceManager的指令。</li><li>监控Container的运行，维护Container的生命周期，监控Container的资源使用情况。</li><li>启动或停止Container，管理任务运行时的依赖包（根据ApplicationMaster的需要，启动Container之前将需要的程序及其依赖包、配置文件等拷贝到本地）。</li></ol><ul><li><p>NodeStatusUpdater: 启动向ResourceManager注册，报告该节点的可用资源情况，通信的端口和后续状态的维护。</p></li><li><p>ContainerManager: 接收RPC请求（启动、停止），资源本地化（下载应用需要的资源到本地，根据需要共享这些资源）。</p><pre><code>PUBLIC: /filecachePRIVATE: /usercache//filecacheAPPLICATION: /usercache//appcache//（在程序完成后会被删除）</code></pre></li><li><p>ContainersLauncher: 加载或终止Container。</p></li><li><p>ContainerMonitor: 监控Container的运行和资源使用情况。</p></li><li><p>ContainerExecutor: 和底层操作系统交互，加载要运行的程序。</p></li></ul><hr><h3 id="YARN-ApplicationMaster"><a href="#YARN-ApplicationMaster" class="headerlink" title="YARN - ApplicationMaster"></a>YARN - ApplicationMaster</h3><p>单个作业的资源管理和任务监控</p><p>具体功能描述：</p><ol><li>计算应用的资源需求，资源可以是静态或动态计算的，静态的一般是Client申请时就指定了，动态则需要ApplicationMaster根据应用的运行状态来决定。</li><li>根据数据来申请对应位置的资源（Data Locality）。</li><li>向ResourceManger申请资源，与NodeManger交互进行程序的运行和监控，监控申请的资源的使用情况，监控作业调度。</li><li>跟踪任务状态和调度，定时向ResourceManger发送心跳信息，报告资源的使用情况和应用的进度信息。</li><li>负责本作业内的任务的容错。</li></ol><p>ApplicationMaster可以是用任何语言编写的程序，它和ResourceManger和NodeManager之间通过protocolBuf交互，以前是一个全局的JobTracker负责的，现在每个左右都一个，可伸缩性更强，至少不会因为作业太多，造成JobTracker瓶颈。同时将作业的逻辑放到一个独立的ApplicationMaster中，使得灵活性更高，每个作业都可以由自己的处理方式，不用绑定到MapReduce的处理模式上。</p><h4 id="如何计算资源需求："><a href="#如何计算资源需求：" class="headerlink" title="如何计算资源需求："></a>如何计算资源需求：</h4><p>一般的MapReduce是根据block数量来定Map和Reduce的计算数量，然后一般的Map或Reduce就占用一个Container。</p><h4 id="如何发现数据的本地化："><a href="#如何发现数据的本地化：" class="headerlink" title="如何发现数据的本地化："></a>如何发现数据的本地化：</h4><h2 id="数据本地化是通过HDFS的block分片信息获取的"><a href="#数据本地化是通过HDFS的block分片信息获取的" class="headerlink" title="数据本地化是通过HDFS的block分片信息获取的"></a>数据本地化是通过HDFS的block分片信息获取的</h2><h3 id="YARN-Container"><a href="#YARN-Container" class="headerlink" title="YARN - Container"></a>YARN - Container</h3><ol><li>基本的资源单位（cpu、内存等）。</li><li>Container可以加载任何程序，而且不限于java。</li><li>一个Node可以包含多个Container，也可以是一个大的Container。</li><li>ApplicationMaster可以根据需要，动态申请和释放Container。</li></ol><hr><h3 id="YARN-Failover"><a href="#YARN-Failover" class="headerlink" title="YARN - Failover"></a>YARN - Failover</h3><p>失败类型</p><ol><li>程序问题。</li><li>进程崩溃。</li><li>硬件问题。</li></ol><p>失败处理</p><p>任务失败</p><ol><li>运行时异常或者JVM退出都会报告给ApplicationMaster。</li><li>通过心跳来检查挂住的任务(timeout)，会检查多次（可配置）才判断该任务是否失效。</li><li>一个作业的任务失败率超过配置，则认为该作业失败。</li><li>失败的任务或作业都会有ApplicationMaster重新运行。<h4 id="ApplicationMaster失败"><a href="#ApplicationMaster失败" class="headerlink" title="ApplicationMaster失败"></a>ApplicationMaster失败</h4></li><li>ApplicationMaster定时发送心跳信号到ResourceManager，通常一旦ApplicationMaster失败，则认为失败，但也可以通过配置多次后才失败</li><li>一旦ApplicationMaster失败，ResourceManager会启动一个新的ApplicationMaster</li><li>新的ApplicationMaster负责恢复之前错误的ApplicationMaster的状(yarn.app.mapreduce.am.job.recovery.enable=true)，这一步是通过将应用运行状态保存到共享的存储上来实现的，ResourceManager不会负责任务状态的保存和恢复</li><li>Client也会定时向ApplicationMaster查询进度和状态，一旦发现其失败，则向ResouceManager询问新的ApplicationMaster<h4 id="NodeManager失败"><a href="#NodeManager失败" class="headerlink" title="NodeManager失败"></a>NodeManager失败</h4></li><li>NodeManager定时发送心跳到ResourceManager，如果超过一段时间没有收到心跳消息，ResourceManager就会将其移除</li><li>任何运行在该NodeManager上的任务和ApplicationMaster都会在其他NodeManager上进行恢复</li><li>如果某个NodeManager失败的次数太多，ApplicationMaster会将其加入黑名单（ResourceManager没有），任务调度时不在其上运行任务<h4 id="ResourceManager失败"><a href="#ResourceManager失败" class="headerlink" title="ResourceManager失败"></a>ResourceManager失败</h4></li><li>通过checkpoint机制，定时将其状态保存到磁盘，然后失败的时候，重新运行</li><li>通过zookeeper同步状态和实现透明的HA</li></ol><p><strong>可以看出，一般的错误处理都是由当前模块的父模块进行监控（心跳）和恢复。而最顶端的模块则通过定时保存、同步状态和zookeeper来ֹ实现HA</strong></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-03 hdfs</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/</url>
    
    <content type="html"><![CDATA[<h2 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h2><p>介绍： hdfs是Hadoop实现的分布式文件系统</p><h3 id="HDFS架构："><a href="#HDFS架构：" class="headerlink" title="HDFS架构："></a>HDFS架构：</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hdfs架构图"><p>1个Master（NameNode/NN） 带 N个Slaves（DataNode/DN）</p><p>blocksize：128M</p><p>NN：负责客户端请求的响应，负责元数据（文件的名称、副本系数、block存放的DN）的管理</p><p>DN：存储用户的文件对应的数据块，要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况。</p><ul><li>NameNode<ol><li>存储文件的metadata，运行时所有数据都保存到内存，整个hdfs可存储的文件数受限于NameNode的内存大小。</li><li>一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果大量小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理的开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件速度。因此，Hadoop建议存储大文件。</li><li>数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode和DateNode的相关信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）</li><li>NameNode失效则整个hdfs都会失效，所以要保证NameNode的可用性。</li></ol></li><li>DataNode<ol><li> 保存具体的block数据。</li><li> 负责数据的读写操作和复杂操作。</li><li>DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息。</li><li>DataNode之间会互相进行通信，复制数据块，保证数据的冗余性。</li></ol></li><li>Block数据块<ol><li>基本存储单位，默认为128M（配置大的块主要是因为a.减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间。b.减少管理块的数据开销，每个块需要在NameNode上有对应的记录。c.对数据块进行读写，减少建立网络的连接成本。）</li><li>一个大文件会被拆成多个块，然后存储于不同的机器。如果一个文件少于block的大小，那么实际占用的空间为文件的大小。</li><li>基本的读写资源，类似于磁盘的页，每次都是读写一个块。</li><li>每个块都是被复制到多台机器，默认是3份。</li></ol></li><li>Secondary NameNode<ol><li>定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的数据传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手动将其设置为主机。</li></ol></li></ul><hr><h3 id="HDFS-写文件"><a href="#HDFS-写文件" class="headerlink" title="HDFS-写文件"></a>HDFS-写文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-write.png" class><ol><li><p>客户端将文件写入本地磁盘的Hdfs Client文件中。</p></li><li><p>当临时文件大小达到一个block的时候，Hdfs Client通知NameNode，申请写入文件。</p></li><li><p>NameNode在Hdfs的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端。</p></li><li><p>客户端收到这些信息后，将临时文件写入DataNodes。</p><ol><li>客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输）。</li><li> 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode。</li><li>以此类推到最后一个DataNode，数据在DataNode之间是通过pipline的方式进行复制的。</li><li>后面的DataNode接受完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端。</li><li>当客户端收到整个block的确认后，会向NameNode发送一个最终的确认信息。</li><li>如果写入某个DataNode失败，数据会继续写人其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性。</li><li>每个block都会有一个校验码，并存放在独立的文件中，以便读的时候来验证其完整性。</li></ol></li><li><p>文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode挂掉，那文件也就丢失了。只保证了数据信息写到NameNode上，并不能保证数据已经被写到了DataNode中）</p><h3 id="Rack-aware（机架感知）"><a href="#Rack-aware（机架感知）" class="headerlink" title="Rack aware（机架感知）"></a>Rack aware（机架感知）</h3><p> 通过配置文件指定机架名和DNS的对应关系</p><p> 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能）</p><p> 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势</p></li></ol><hr><h3 id="HDFS-读文件"><a href="#HDFS-读文件" class="headerlink" title="HDFS-读文件"></a>HDFS-读文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-read.png" class><ol><li>客户端向NameNode发送读取请求。</li><li>NameNode返回文件所有Block和这些block所在的DataNodes(包括复制节点)</li><li>客户端直接从DataNode中读取数据，如果该DataNode读取失败(DataNode失效或校验码不对)，则从复制节点中读取(如果读取的数据就在本机，则直接读取，否则通过网络读取)。</li></ol><hr><h3 id="HDFS-可靠性"><a href="#HDFS-可靠性" class="headerlink" title="HDFS-可靠性"></a>HDFS-可靠性</h3><ul><li>冗余副本策略<ul><li>可以在hdfs-site.xml中设置复制因子指定副本数量。<br>所有数据块都可副本。</li><li>DataNode启动时，遍历本地文件系统，产生一份HDFS数据块和本地文件对应关系列表(blockreport)汇报给NameNode。</li></ul></li><li>机架策略<ul><li>HDFS的“机架感知”，通过节点之间发送一个数据包，来判断他们是否在同一个机架。</li><li>一般本机架放一个副本，在其他机架再存放一个副本，这样可以防止机架失效时丢失数据，也可以提高带宽利用率。</li></ul></li><li>心跳机制<ul><li>NataNode定期从DataNode接受心跳信息和块报告。</li><li>NameNode根据块报告验证元数据。</li><li>没有按时发送心跳的DataNode会被标记为宕机，不会再给他任何i/o请求。</li><li>如果DataNode失效造成副本数量下降，并且低于预先设置的值，NameNode会检测这些数据库，并在合适的时间重新复制。</li><li>引发重新复制的原因还包括数据副本本身损坏，磁盘错误，复制因子被增大等。</li></ul></li><li>安全模式<ul><li>NameNode启动时会经过一个“安全模式”阶段。</li><li>安全模式阶段不会产生数据写。</li><li>在此阶段NameNode收集各个DataNode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的。</li><li>在一定比例(可设置)的数据块被确定为“安全”后，再过若干时间，安全模式结束。</li><li>当检测到副本不足数据块时，该块会被复制，直到达到最小副本数。</li></ul></li><li>检验和<ul><li>在文件创立时，每个块都产生校验和。</li><li>校验和会作为单独一个隐藏文件保存在命名空间下。</li><li>客户端获取数据时可以检查校验和是否相同，从而发现数据块是否损坏。</li><li>如果正在读取的数据块损坏，则可以继续读取其他副本。</li></ul></li><li>回收站<ul><li>删除文件时，其实是放入回收站/trach中。</li><li>回收站里的文件是可以快速恢复的。</li><li>可以设置一个时间值，当回收站里的文件的存放时间超过这个值，就被彻底删除，并且释放占用的数据块。</li></ul></li><li>元数据保护<ul><li>映像文件和事务日志是NameNode的核心数据，可以配置为拥有多个副本。</li><li>副本会降低NameNode的处理速度，但增加安全性。</li><li>NameNode依然是单点，如果发生故障需要切换。</li></ul></li><li>快照机制</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-02 环境搭建</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="Hadoop-环境搭建"><a href="#Hadoop-环境搭建" class="headerlink" title="Hadoop 环境搭建"></a>Hadoop 环境搭建</h2><ol><li><p>安装jdk</p></li><li><p>安装ssh 设置免密登录</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arcade">ssh-keygen -t rsa<br>cp ~<span class="hljs-regexp">/.ssh/i</span>d_rsa_.pub ~<span class="hljs-regexp">/.ssh/</span>authorized_keys<br></code></pre></td></tr></table></figure></li><li><p>Hadoop 环境安装</p><p><code>/etc/hadoop/hadoop-env.sh</code> 修改<code>java_home</code><br>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><ul><li>3.1  <code>core-site.xml</code><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-params">&lt;configuration&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>fs.defaultFS<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span>hdfs:<span class="hljs-comment">//172.16.100.151:8020&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>hadoop.tmp.dir<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/home/</span>hadoop<span class="hljs-meta-keyword">/app/</span>tmp<span class="hljs-params">&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br><span class="hljs-params">&lt;/configuration&gt;</span><br></code></pre></td></tr></table></figure></li><li>3.2 <code>hdfs-site.xml</code><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!--副本个数--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><code>解决安全模式问题</code> “hadoop Cannot create directory Name node is in safe mode.”</li></ul></li></ol><p>离开安全模式方法：<code>bin/hadoop dfsadmin -safemode leave</code></p><h3 id="yarn-环境搭建："><a href="#yarn-环境搭建：" class="headerlink" title="yarn 环境搭建："></a>yarn 环境搭建：</h3><ol><li><p><code>etc/hadoop/mapred-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><p><code>etc/hadoop/yarn-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><p>服务启动：</p></li></ol><p><code>sbin/start-yarn.sh</code></p><p>服务停止：</p><p><code>sbin/stop-yarn.sh</code></p><p>ResourceManager - <a href="http://localhost:8088/">http://localhost:8088/</a></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-01  初识Hadoop</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/</url>
    
    <content type="html"><![CDATA[<h2 id="初识Hadoop"><a href="#初识Hadoop" class="headerlink" title="初识Hadoop"></a>初识Hadoop</h2><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><p>适合</p><ul><li>大规模数据</li><li>流式数据（写一次，读多次）</li><li>商用硬件（一般硬件）</li></ul><p>不适合</p><ul><li>低延时的数据访问</li><li>大量的小文件</li><li>频繁修改文件（基本就是写1次）<h2 id="Hadoop架构"><a href="#Hadoop架构" class="headerlink" title="Hadoop架构"></a>Hadoop架构</h2><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/hadoop%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hadoop架构图"></li><li>分布式文件系统hdfs</li><li>分布式资源调度yarn</li><li>分布式计算框架MapReduce</li><li>Others: 利用YARN的资源管理功能实现其他的数据处理方式</li></ul><p>hadoop包含的模块：</p><ul><li>hadoop common  – 公共模块</li><li>hadoop distributed file system（hdfs）–提供数据存储</li><li>Hadoop yarn – 作业调度，资源管理</li><li>hadoop MapReduce –yarn之上并行处理框架</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
