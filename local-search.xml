<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>zookeeper-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/</url>
    
    <content type="html"><![CDATA[<h2 id="zookeeper环境搭建"><a href="#zookeeper环境搭建" class="headerlink" title="zookeeper环境搭建"></a>zookeeper环境搭建</h2><p>新建文件docker-compose-zk.yml</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs"><span class="hljs-attribute">version</span>: &#x27;3.1&#x27;<br><br><span class="hljs-attribute">services:</span><br>  zoo1:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo1<br>    ports:<br>      - 2181:2181<br>    environment:<br>      ZOO_MY_ID: 1<br>      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo2:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo2<br>    ports:<br>      - 2182:2181<br>    environment:<br>      ZOO_MY_ID: 2<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo3:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo3<br>    ports:<br>      - 2183:2181<br>    environment:<br>      ZOO_MY_ID: 3<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181<br></code></pre></td></tr></table></figure><p>在目录下执行<code>docker-compose -f docker-compose-zk.yml up -d</code></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>rocketMQ-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/</url>
    
    <content type="html"><![CDATA[<h2 id="rocketMQ环境搭建"><a href="#rocketMQ环境搭建" class="headerlink" title="rocketMQ环境搭建"></a>rocketMQ环境搭建</h2><p><code>git clone https://github.com/foxiswho/docker-rocketmq.git</code></p><p>切换分支<code>git checkout v4.4.0</code></p><p>该项目目录结构为</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">docker-rocketmq</span>/<br>├── <span class="hljs-selector-tag">base</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│   └── <span class="hljs-selector-tag">scripts</span><br>│       ├── <span class="hljs-selector-tag">runbroker-customize</span><span class="hljs-selector-class">.sh</span><br>│       ├── <span class="hljs-selector-tag">runserver-customize</span><span class="hljs-selector-class">.sh</span><br>│       └── <span class="hljs-selector-tag">to_bytes</span><span class="hljs-selector-class">.gawk</span><br>├── <span class="hljs-selector-tag">broker</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">README</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">rmq</span>   #进入此目录<br>│   ├── <span class="hljs-selector-tag">docker-compose</span><span class="hljs-selector-class">.yml</span><br>│   └── <span class="hljs-selector-tag">rmq</span><br>│       ├── <span class="hljs-selector-tag">brokerconf</span><br>│       │   └── <span class="hljs-selector-tag">broker</span><span class="hljs-selector-class">.conf</span><br>│       ├── <span class="hljs-selector-tag">logs</span><br>│       ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│       └── <span class="hljs-selector-tag">store</span><br>└── <span class="hljs-selector-tag">server</span><br>    ├── <span class="hljs-selector-tag">Dockerfile</span><br>    └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br></code></pre></td></tr></table></figure><p>进入rmq目录下，执行<code>docker-compose up</code> 即可。</p><p>启动IP,如果 docker 报 <code>com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed</code>修改<br><code>broker.conf</code> 文件里brokerIP1设置为宿主ip即可</p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>elastic-search-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/</url>
    
    <content type="html"><![CDATA[<h2 id="elastic-search环境搭建"><a href="#elastic-search环境搭建" class="headerlink" title="elastic-search环境搭建"></a>elastic-search环境搭建</h2><p>创建目录结构为</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">docker</span>-es/<br>├── docker-compose.yaml<br>├── master<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>├── node1<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>└── node2<br>    ├── conf<br>    │   └── elasticsearch.yml<br>    ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>    └── logs<br></code></pre></td></tr></table></figure><p><code>docker-compose.yaml</code> 文件内容：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs awk">version: <span class="hljs-string">&#x27;3&#x27;</span><br>services:<br>     es-master:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-master<br>       restart: always<br>       volumes:<br>         - .<span class="hljs-regexp">/master/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/master/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/master/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>       ports:<br>         - <span class="hljs-string">&quot;9200:9200&quot;</span><br>         - <span class="hljs-string">&quot;9300:9300&quot;</span><br>       environment:<br>         - <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;</span><br>                 <br>     es-node1:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node1<br>       <span class="hljs-comment">#restart: always</span><br>       volumes:<br>         - .<span class="hljs-regexp">/node1/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/node1/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/node1/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-node2:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node2<br>       restart: always<br>       volumes:<br>        - .<span class="hljs-regexp">/node2/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>        - .<span class="hljs-regexp">/node2/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>        - .<span class="hljs-regexp">/node2/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-head:<br>       image: tobias74/elasticsearch-head:<span class="hljs-number">6</span><br>       container_name: es-head<br>       restart: always<br>       ports:<br>       - <span class="hljs-string">&quot;9100:9100&quot;</span><br></code></pre></td></tr></table></figure><p><code>master/conf/elasticsearch.yml</code> 文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">bootstrap.memory_lock:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">cluster.name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br><span class="hljs-attr">node.name:</span> <span class="hljs-string">&quot;es-master&quot;</span><br><span class="hljs-attr">node.master:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">network.host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">http.port:</span> <span class="hljs-number">9200</span><br><span class="hljs-attr">transport.tcp.port:</span> <span class="hljs-number">9300</span><br><span class="hljs-attr">discovery.seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>]<br><span class="hljs-attr">discovery.zen.minimum_master_nodes:</span> <span class="hljs-number">1</span><br><span class="hljs-attr">cluster.initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br><br><span class="hljs-attr">http.cors.enabled:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">http.cors.allow-origin:</span> <span class="hljs-string">&quot;*&quot;</span><br><span class="hljs-attr">xpack.security.audit.enabled:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p><code>node1/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node1&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9201</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9301</span><br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br><br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br><br>http.cors.<span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br>http.cors.allow-<span class="hljs-attr">origin:</span> <span class="hljs-string">&quot;*&quot;</span><br></code></pre></td></tr></table></figure><p><code>node2/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node2&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9202</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9302</span><br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br></code></pre></td></tr></table></figure><p><code>docker-compose up</code> 启动即可</p><h2 id="启动错误解决"><a href="#启动错误解决" class="headerlink" title="启动错误解决"></a>启动错误解决</h2><ol><li>docker以挂载配置文件启动elasticsearch的时候会报错误，所以需要给予文件夹权限<br>赋权命令：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">chmod <span class="hljs-number">777</span> master<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node1<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node2<span class="hljs-regexp">/data/</span><br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-run</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/</url>
    
    <content type="html"><![CDATA[<h2 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h2><p>安装命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">streamsets</span><br><span class="hljs-attribute">docker</span> run --restart <span class="hljs-literal">on</span>-failure -p <span class="hljs-number">18630</span>:<span class="hljs-number">18630</span> -d --name sdc streamsets/datacollector<br><br><span class="hljs-attribute">pgsql</span><br><span class="hljs-attribute">docker</span> run --name postgres -e POSTGRES_PASSWORD=postgres<span class="hljs-number">369</span> -p <span class="hljs-number">5432</span>:<span class="hljs-number">5432</span> -d postgres:<span class="hljs-number">9</span>.<span class="hljs-number">5</span>.<span class="hljs-number">24</span>-alpine<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-centos7</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装docker"><a href="#centos7安装docker" class="headerlink" title="centos7安装docker"></a>centos7安装docker</h2><p>安装命令：<br><code>yum install -y docker </code></p><p>启动docker<br><code>systemctl start docker</code></p><p>设置docker开机启动<br><code>systemctl enable docker</code></p><p>##安装docker-compose</p><ol><li><p>添加EPEL源</p><p> <code>yum install -y epel-release</code></p></li><li><p>安装python-pip</p><p> <code>yum install -y python-pip</code></p></li><li><p>安装docker-compose</p><p> <code>pip install docker-compose</code></p></li></ol><p>##更换镜像源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs awk">打开文件（没有就新建）<br>vim <span class="hljs-regexp">/etc/</span>docker/daemon.json<br><br>&#123;<br><span class="hljs-string">&quot;registry-mirrors&quot;</span>: [<span class="hljs-string">&quot;http://hub-mirror.c.163.com&quot;</span>]<br>&#125;<br>保存后重启即可<br>service docker restart<br><br>Docker中国区官方镜像<br>https:<span class="hljs-regexp">//</span>registry.docker-cn.com<br><br>网易<br>http:<span class="hljs-regexp">//</span>hub-mirror.c.<span class="hljs-number">163</span>.com<br><br>ustc <br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>中国科技大学<br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>阿里云容器服务(需要先创建容器镜像)<br>https:<span class="hljs-regexp">//</span>cr.console.aliyun.com/<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux常见问题</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<ol><li><p><code>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</code></p><p>解决：<code>sysctl -w vm.max_map_count=262144</code></p><p>重启虚拟机将失效<br>在<code>/etc/sysctl.conf</code>文件最后添加一行<br><code>vm.max_map_count=262144</code>即可永久修改</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>centos7安装MySQL</title>
    <link href="/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/"/>
    <url>/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装MySQL"><a href="#centos7安装MySQL" class="headerlink" title="centos7安装MySQL"></a>centos7安装MySQL</h2><ol><li><p>配置YUM源</p><p> <code>wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum localinstall mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum repolist enabled | grep &quot;mysql.*-community.*&quot;</code></p><p> 可以修改<code>vim /etc/yum.repos.d/mysql-community.repo</code>源，改变默认安装的mysql版本。比如要安装5.6版本，将5.7源的enabled=1改成enabled=0。然后再将5.6源的enabled=0改成enabled=1即可。</p></li><li><p>安装MySQL</p><p> <code>yum install mysql-community-server</code></p></li><li><p>启动MySQL服务</p><p> <code>service mysqld start</code></p></li><li><p>开机启动</p><p> <code>systemctl enable mysqld</code></p><p> <code>systemctl daemon-reload</code></p></li><li><p>修改root本地登录密码</p><p> <code>grep &#39;temporary password&#39; /var/log/mysqld.log   ---AkY&gt;ts#9)Dcv</code></p><p> <code>mysql -uroot -p</code></p><p> <code>ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;a1b2c3d4&#39;; </code></p><p> 修改密码策略</p><p> 在<code>/etc/my.cnf</code>文件添加validate_password_policy配置，指定密码策略<br>选择0（LOW），1（MEDIUM），2（STRONG）其中一种，选择2需要提供密码字典文件<br>validate_password_policy=0</p><p> 如果不需要密码策略，添加my.cnf文件中添加如下配置禁用即可：<br><code>validate_password = off</code></p></li><li><p>添加远程登录用户</p><p> 默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户：<br> mysql&gt; <code>GRANT ALL PRIVILEGES ON *.* TO &#39;mysql&#39;@&#39;%&#39; IDENTIFIED BY &#39;mysql123&#39; WITH GRANT OPTION;</code></p><p> 设置root用户远程登录</p><pre><code> use mysql; update user set host = &#39;%&#39; where user = &#39;root&#39;; FLUSH PRIVILEGES;</code></pre></li><li><p>配置默认编码为utf8</p><p> 修改<code>/etc/my.cnf</code>配置文件，在[mysqld]下添加编码配置，如下所示：</p><p> [mysqld]</p><p> character_set_server=utf8</p><p> init_connect=’SET NAMES utf8’</p></li><li><p>不区分大小写</p><p> 在<code>[mysqld]</code>下加上<code>lower_case_table_names=1</code></p></li><li><p>mysql重启服务</p><p> <code>service mysqld restart</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于gitee+hexo搭建个人博客</title>
    <link href="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/"/>
    <url>/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/</url>
    
    <content type="html"><![CDATA[<p>什么是 Hexo？</p><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。  —来自hexo官网<br><code>https://hexo.io/zh-cn/docs/</code></p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>nodejs</li><li>git</li></ul><ol><li><p>安装hexo。 （npm默认镜像源在国外，会有下载失败情况，建议更换taobao镜像源）</p><p> <code>$ npm install -g hexo-cli</code></p></li><li><p>新建个人文件夹，初始化目录为hexo目录。命令如下：</p><pre><code> $ hexo init $ npm install 执行完毕后目录如下： hexo  ├── _config.landscape.yml ├── _config.yml ├── node_modules ├── package-lock.json ├── package.json ├── scaffolds ├── source └── themes</code></pre></li><li><p>启动hexo</p></li></ol><p>在hexo目录下执行 <code>hexo server</code></p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/hexo%E5%90%AF%E5%8A%A8%E5%9B%BE.png" class><p>浏览器访问<strong><a href="http://localhost:4000/">http://localhost:4000</a></strong> 即可</p><h2 id="gitee网站配置"><a href="#gitee网站配置" class="headerlink" title="gitee网站配置"></a>gitee网站配置</h2><ol><li><p>在gitee新建仓库*<strong>.gitee.io</strong> (*号为任意名称)</p></li><li><p>修改<code>_config.yml</code>文件</p><pre><code> 这里只截取部分配置信息 # URL ## If your site is put in a subdirectory, set url as &#39;http://example.com/child&#39; and root as &#39;/child/&#39; url: 后续需要修改  root: 同目录名  deploy:   type: &#39;git&#39;   repo: git仓库地址   如： https://gitee.com/test/test   branch: master   message: blog update</code></pre></li><li><p>安装插件 <code>npm install --save hexo-deployer-git</code></p></li><li><p>执行命令<code>hexo g -d</code> 这里会提示用户名密码，成功后在gitee页面可以看到本地代码已提交到仓库中。</p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/gitee-pages.png" class></li><li><p>如图操作后点击启动，成功后复制网站地址，访问发现静态资源没有加载。</p></li></ol><ul><li>将配置文件中的url修改为网站地址 例如： <a href="http://ccqi3.gitee.io/test">http://ccqi3.gitee.io/test</a></li><li>root 后是仓库名称如 root: /test/</li></ul><ol start="6"><li>修改完后在hexo目录下再次执行<code>hexo g -d</code> (以后配置有调整或者发布新的文章都用此命令即可)</li><li>在gitee的pages页面里点击更新，再次访问网址发现已经搭建好博客了。</li></ol><h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><ul><li>修改<code>_config.yml</code> 文件中的 <code>post_asset_folder:false</code> 改为 <strong>true</strong><br>这样新建文档时会在文档同级生成同名文件夹，图片资源放入其中。</li><li>安装插件<br><code>npm install https://github.com/7ym0n/hexo-asset-image --save</code></li></ul><p><code>&#123;% asset_img test.jpg This is an test image %&#125;</code><br>test.jpg 就是图片文件名称 后面文字是图片描述</p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p><code>hexo generate</code></p><p><code>hexo server</code></p><p><code>hexo deploy</code></p><p><code>hexo clean</code></p><p><code>hexo new page &quot;type&quot; </code> <strong>type</strong> 如下：</p><table><thead><tr><th>page</th><th>type</th><th>内容</th></tr></thead><tbody><tr><td>tages</td><td>tages</td><td>标签</td></tr><tr><td>categories</td><td>categories</td><td>分类</td></tr><tr><td>archives</td><td>archives</td><td>博客</td></tr><tr><td>about</td><td>about</td><td>关于</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的博客</title>
    <link href="/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    <url>/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="为什么要写博客"><a href="#为什么要写博客" class="headerlink" title="为什么要写博客"></a>为什么要写博客</h2><ul><li>生活记录</li><li>编程笔记</li></ul>]]></content>
    
    
    <categories>
      
      <category>个人计划</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-03 hdfs</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/</url>
    
    <content type="html"><![CDATA[<h2 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h2><p>介绍： hdfs是Hadoop实现的分布式文件系统</p><h3 id="HDFS架构："><a href="#HDFS架构：" class="headerlink" title="HDFS架构："></a>HDFS架构：</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hdfs架构图"><p>1个Master（NameNode/NN） 带 N个Slaves（DataNode/DN）</p><p>blocksize：128M</p><p>NN：负责客户端请求的响应，负责元数据（文件的名称、副本系数、block存放的DN）的管理</p><p>DN：存储用户的文件对应的数据块，要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况。</p><ul><li>NameNode<ol><li>存储文件的metadata，运行时所有数据都保存到内存，整个hdfs可存储的文件数受限于NameNode的内存大小。</li><li>一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果大量小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理的开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件速度。因此，Hadoop建议存储大文件。</li><li>数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode和DateNode的相关信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）</li><li>NameNode失效则整个hdfs都会失效，所以要保证NameNode的可用性。</li></ol></li><li>DataNode<ol><li> 保存具体的block数据。</li><li> 负责数据的读写操作和复杂操作。</li><li>DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息。</li><li>DataNode之间会互相进行通信，复制数据块，保证数据的冗余性。</li></ol></li><li>Block数据块<ol><li>基本存储单位，默认为128M（配置大的块主要是因为a.减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间。b.减少管理块的数据开销，每个块需要在NameNode上有对应的记录。c.对数据块进行读写，减少建立网络的连接成本。）</li><li>一个大文件会被拆成多个块，然后存储于不同的机器。如果一个文件少于block的大小，那么实际占用的空间为文件的大小。</li><li>基本的读写资源，类似于磁盘的页，每次都是读写一个块。</li><li>每个块都是被复制到多台机器，默认是3份。</li></ol></li><li>Secondary NameNode<ol><li>定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的数据传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手动将其设置为主机。</li></ol></li></ul><hr><h3 id="HDFS-写文件"><a href="#HDFS-写文件" class="headerlink" title="HDFS-写文件"></a>HDFS-写文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-write.png" class><ol><li><p>客户端将文件写入本地磁盘的Hdfs Client文件中。</p></li><li><p>当临时文件大小达到一个block的时候，Hdfs Client通知NameNode，申请写入文件。</p></li><li><p>NameNode在Hdfs的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端。</p></li><li><p>客户端收到这些信息后，将临时文件写入DataNodes。</p><ol><li>客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输）。</li><li> 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode。</li><li>以此类推到最后一个DataNode，数据在DataNode之间是通过pipline的方式进行复制的。</li><li>后面的DataNode接受完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端。</li><li>当客户端收到整个block的确认后，会向NameNode发送一个最终的确认信息。</li><li>如果写入某个DataNode失败，数据会继续写人其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性。</li><li>每个block都会有一个校验码，并存放在独立的文件中，以便读的时候来验证其完整性。</li></ol></li><li><p>文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode挂掉，那文件也就丢失了。只保证了数据信息写到NameNode上，并不能保证数据已经被写到了DataNode中）</p><h3 id="Rack-aware（机架感知）"><a href="#Rack-aware（机架感知）" class="headerlink" title="Rack aware（机架感知）"></a>Rack aware（机架感知）</h3><p> 通过配置文件指定机架名和DNS的对应关系</p><p> 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能）</p><p> 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势</p></li></ol><hr><h3 id="HDFS-读文件"><a href="#HDFS-读文件" class="headerlink" title="HDFS-读文件"></a>HDFS-读文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-read.png" class><ol><li>客户端向NameNode发送读取请求。</li><li>NameNode返回文件所有Block和这些block所在的DataNodes(包括复制节点)</li><li>客户端直接从DataNode中读取数据，如果该DataNode读取失败(DataNode失效或校验码不对)，则从复制节点中读取(如果读取的数据就在本机，则直接读取，否则通过网络读取)。</li></ol><hr><h3 id="HDFS-可靠性"><a href="#HDFS-可靠性" class="headerlink" title="HDFS-可靠性"></a>HDFS-可靠性</h3><ul><li>冗余副本策略<ul><li>可以在hdfs-site.xml中设置复制因子指定副本数量。<br>所有数据块都可副本。</li><li>DataNode启动时，遍历本地文件系统，产生一份HDFS数据块和本地文件对应关系列表(blockreport)汇报给NameNode。</li></ul></li><li>机架策略<ul><li>HDFS的“机架感知”，通过节点之间发送一个数据包，来判断他们是否在同一个机架。</li><li>一般本机架放一个副本，在其他机架再存放一个副本，这样可以防止机架失效时丢失数据，也可以提高带宽利用率。</li></ul></li><li>心跳机制<ul><li>NataNode定期从DataNode接受心跳信息和块报告。</li><li>NameNode根据块报告验证元数据。</li><li>没有按时发送心跳的DataNode会被标记为宕机，不会再给他任何i/o请求。</li><li>如果DataNode失效造成副本数量下降，并且低于预先设置的值，NameNode会检测这些数据库，并在合适的时间重新复制。</li><li>引发重新复制的原因还包括数据副本本身损坏，磁盘错误，复制因子被增大等。</li></ul></li><li>安全模式<ul><li>NameNode启动时会经过一个“安全模式”阶段。</li><li>安全模式阶段不会产生数据写。</li><li>在此阶段NameNode收集各个DataNode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的。</li><li>在一定比例(可设置)的数据块被确定为“安全”后，再过若干时间，安全模式结束。</li><li>当检测到副本不足数据块时，该块会被复制，直到达到最小副本数。</li></ul></li><li>检验和<ul><li>在文件创立时，每个块都产生校验和。</li><li>校验和会作为单独一个隐藏文件保存在命名空间下。</li><li>客户端获取数据时可以检查校验和是否相同，从而发现数据块是否损坏。</li><li>如果正在读取的数据块损坏，则可以继续读取其他副本。</li></ul></li><li>回收站<ul><li>删除文件时，其实是放入回收站/trach中。</li><li>回收站里的文件是可以快速恢复的。</li><li>可以设置一个时间值，当回收站里的文件的存放时间超过这个值，就被彻底删除，并且释放占用的数据块。</li></ul></li><li>元数据保护<ul><li>映像文件和事务日志是NameNode的核心数据，可以配置为拥有多个副本。</li><li>副本会降低NameNode的处理速度，但增加安全性。</li><li>NameNode依然是单点，如果发生故障需要切换。</li></ul></li><li>快照机制</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-02 环境搭建</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="Hadoop-环境搭建"><a href="#Hadoop-环境搭建" class="headerlink" title="Hadoop 环境搭建"></a>Hadoop 环境搭建</h2><ol><li><p>安装jdk</p></li><li><p>安装ssh 设置免密登录</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arcade">ssh-keygen -t rsa<br>cp ~<span class="hljs-regexp">/.ssh/i</span>d_rsa_.pub ~<span class="hljs-regexp">/.ssh/</span>authorized_keys<br></code></pre></td></tr></table></figure></li><li><p>Hadoop 环境安装</p><p><code>/etc/hadoop/hadoop-env.sh</code> 修改<code>java_home</code><br>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><ul><li>3.1  <code>core-site.xml</code><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-params">&lt;configuration&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>fs.defaultFS<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span>hdfs:<span class="hljs-comment">//172.16.100.151:8020&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>hadoop.tmp.dir<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/home/</span>hadoop<span class="hljs-meta-keyword">/app/</span>tmp<span class="hljs-params">&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br><span class="hljs-params">&lt;/configuration&gt;</span><br></code></pre></td></tr></table></figure></li><li>3.2 <code>hdfs-site.xml</code><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!--副本个数--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><code>解决安全模式问题</code> “hadoop Cannot create directory Name node is in safe mode.”</li></ul></li></ol><p>离开安全模式方法：<code>bin/hadoop dfsadmin -safemode leave</code></p><h3 id="yarn-环境搭建："><a href="#yarn-环境搭建：" class="headerlink" title="yarn 环境搭建："></a>yarn 环境搭建：</h3><ol><li><p><code>etc/hadoop/mapred-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><p><code>etc/hadoop/yarn-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><p>服务启动：</p></li></ol><p><code>sbin/start-yarn.sh</code></p><p>服务停止：</p><p><code>sbin/stop-yarn.sh</code></p><p>ResourceManager - <a href="http://localhost:8088/">http://localhost:8088/</a></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-01  初识Hadoop</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/</url>
    
    <content type="html"><![CDATA[<h2 id="初识Hadoop"><a href="#初识Hadoop" class="headerlink" title="初识Hadoop"></a>初识Hadoop</h2><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><p>适合</p><ul><li>大规模数据</li><li>流式数据（写一次，读多次）</li><li>商用硬件（一般硬件）</li></ul><p>不适合</p><ul><li>低延时的数据访问</li><li>大量的小文件</li><li>频繁修改文件（基本就是写1次）<h2 id="Hadoop架构"><a href="#Hadoop架构" class="headerlink" title="Hadoop架构"></a>Hadoop架构</h2><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01/hadoop%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hadoop架构图"></li><li>分布式文件系统hdfs</li><li>分布式资源调度yarn</li><li>分布式计算框架MapReduce</li><li>Others: 利用YARN的资源管理功能实现其他的数据处理方式</li></ul><p>hadoop包含的模块：</p><ul><li>hadoop common  – 公共模块</li><li>hadoop distributed file system（hdfs）–提供数据存储</li><li>Hadoop yarn – 作业调度，资源管理</li><li>hadoop MapReduce –yarn之上并行处理框架</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
