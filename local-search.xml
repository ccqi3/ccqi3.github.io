<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>zookeeper-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-zk/</url>
    
    <content type="html"><![CDATA[<h2 id="zookeeper环境搭建"><a href="#zookeeper环境搭建" class="headerlink" title="zookeeper环境搭建"></a>zookeeper环境搭建</h2><p>新建文件docker-compose-zk.yml</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs"><span class="hljs-attribute">version</span>: &#x27;3.1&#x27;<br><br><span class="hljs-attribute">services:</span><br>  zoo1:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo1<br>    ports:<br>      - 2181:2181<br>    environment:<br>      ZOO_MY_ID: 1<br>      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo2:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo2<br>    ports:<br>      - 2182:2181<br>    environment:<br>      ZOO_MY_ID: 2<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181<br><br>  zoo3:<br>    image: zookeeper<br>    restart: always<br>    hostname: zoo3<br>    ports:<br>      - 2183:2181<br>    environment:<br>      ZOO_MY_ID: 3<br>      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181<br></code></pre></td></tr></table></figure><p>在目录下执行<code>docker-compose -f docker-compose-zk.yml up -d</code></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>rocketMQ-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-rocketMQ/</url>
    
    <content type="html"><![CDATA[<h2 id="rocketMQ环境搭建"><a href="#rocketMQ环境搭建" class="headerlink" title="rocketMQ环境搭建"></a>rocketMQ环境搭建</h2><p><code>git clone https://github.com/foxiswho/docker-rocketmq.git</code></p><p>切换分支<code>git checkout v4.4.0</code></p><p>该项目目录结构为</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">docker-rocketmq</span>/<br>├── <span class="hljs-selector-tag">base</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│   └── <span class="hljs-selector-tag">scripts</span><br>│       ├── <span class="hljs-selector-tag">runbroker-customize</span><span class="hljs-selector-class">.sh</span><br>│       ├── <span class="hljs-selector-tag">runserver-customize</span><span class="hljs-selector-class">.sh</span><br>│       └── <span class="hljs-selector-tag">to_bytes</span><span class="hljs-selector-class">.gawk</span><br>├── <span class="hljs-selector-tag">broker</span><br>│   ├── <span class="hljs-selector-tag">Dockerfile</span><br>│   └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">README</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">rmq</span>   #进入此目录<br>│   ├── <span class="hljs-selector-tag">docker-compose</span><span class="hljs-selector-class">.yml</span><br>│   └── <span class="hljs-selector-tag">rmq</span><br>│       ├── <span class="hljs-selector-tag">brokerconf</span><br>│       │   └── <span class="hljs-selector-tag">broker</span><span class="hljs-selector-class">.conf</span><br>│       ├── <span class="hljs-selector-tag">logs</span><br>│       ├── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br>│       └── <span class="hljs-selector-tag">store</span><br>└── <span class="hljs-selector-tag">server</span><br>    ├── <span class="hljs-selector-tag">Dockerfile</span><br>    └── <span class="hljs-selector-tag">readme</span><span class="hljs-selector-class">.md</span><br></code></pre></td></tr></table></figure><p>进入rmq目录下，执行<code>docker-compose up</code> 即可。</p><p>启动IP,如果 docker 报 <code>com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed</code>修改<br><code>broker.conf</code> 文件里brokerIP1设置为宿主ip即可</p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>elastic-search-环境搭建</title>
    <link href="/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/"/>
    <url>/blog/2021/01/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-compose-elastic-search/</url>
    
    <content type="html"><![CDATA[<h2 id="elastic-search环境搭建"><a href="#elastic-search环境搭建" class="headerlink" title="elastic-search环境搭建"></a>elastic-search环境搭建</h2><p>创建目录结构为</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">docker</span>-es/<br>├── docker-compose.yaml<br>├── master<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>├── node1<br>│   ├── conf<br>│   │   └── elasticsearch.yml<br>│   ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>│   └── logs<br>└── node2<br>    ├── conf<br>    │   └── elasticsearch.yml<br>    ├── <span class="hljs-class"><span class="hljs-keyword">data</span></span><br>    └── logs<br></code></pre></td></tr></table></figure><p><code>docker-compose.yaml</code> 文件内容：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs awk">version: <span class="hljs-string">&#x27;3&#x27;</span><br>services:<br>     es-master:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-master<br>       restart: always<br>       volumes:<br>         - .<span class="hljs-regexp">/master/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/master/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/master/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>       ports:<br>         - <span class="hljs-string">&quot;9200:9200&quot;</span><br>         - <span class="hljs-string">&quot;9300:9300&quot;</span><br>       environment:<br>         - <span class="hljs-string">&quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;</span><br>                 <br>     es-node1:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node1<br>       <span class="hljs-comment">#restart: always</span><br>       volumes:<br>         - .<span class="hljs-regexp">/node1/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>         - .<span class="hljs-regexp">/node1/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>         - .<span class="hljs-regexp">/node1/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-node2:<br>       image:  elasticsearch:<span class="hljs-number">7.6</span>.<span class="hljs-number">0</span><br>       container_name: es-node2<br>       restart: always<br>       volumes:<br>        - .<span class="hljs-regexp">/node2/</span>data:<span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>data:rw<br>        - .<span class="hljs-regexp">/node2/</span>conf<span class="hljs-regexp">/elasticsearch.yml:/u</span>sr<span class="hljs-regexp">/share/</span>elasticsearch<span class="hljs-regexp">/config/</span>elasticsearch.yml<br>        - .<span class="hljs-regexp">/node2/</span>logs:<span class="hljs-regexp">/user/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs:rw<br>     es-head:<br>       image: tobias74/elasticsearch-head:<span class="hljs-number">6</span><br>       container_name: es-head<br>       restart: always<br>       ports:<br>       - <span class="hljs-string">&quot;9100:9100&quot;</span><br></code></pre></td></tr></table></figure><p><code>master/conf/elasticsearch.yml</code> 文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">bootstrap.memory_lock:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">cluster.name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br><span class="hljs-attr">node.name:</span> <span class="hljs-string">&quot;es-master&quot;</span><br><span class="hljs-attr">node.master:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">node.data:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">network.host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">http.port:</span> <span class="hljs-number">9200</span><br><span class="hljs-attr">transport.tcp.port:</span> <span class="hljs-number">9300</span><br><span class="hljs-attr">discovery.seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>]<br><span class="hljs-attr">discovery.zen.minimum_master_nodes:</span> <span class="hljs-number">1</span><br><span class="hljs-attr">cluster.initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br><br><span class="hljs-attr">http.cors.enabled:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">http.cors.allow-origin:</span> <span class="hljs-string">&quot;*&quot;</span><br><span class="hljs-attr">xpack.security.audit.enabled:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p><code>node1/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node1&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9201</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9301</span><br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br><br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br><br>http.cors.<span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br>http.cors.allow-<span class="hljs-attr">origin:</span> <span class="hljs-string">&quot;*&quot;</span><br></code></pre></td></tr></table></figure><p><code>node2/conf/elasticsearch.yml</code>  文件内容:</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs groovy">cluster.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-cluster&quot;</span><br>node.<span class="hljs-attr">name:</span> <span class="hljs-string">&quot;es-node2&quot;</span><br>node.<span class="hljs-attr">master:</span> <span class="hljs-literal">false</span><br>node.<span class="hljs-attr">data:</span> <span class="hljs-literal">true</span><br>network.<span class="hljs-attr">host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>http.<span class="hljs-attr">port:</span> <span class="hljs-number">9202</span><br>transport.tcp.<span class="hljs-attr">port:</span> <span class="hljs-number">9302</span><br>discovery.<span class="hljs-attr">seed_hosts:</span> [<span class="hljs-string">&quot;127.0.0.1:9300&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9301&quot;</span>,<span class="hljs-string">&quot;127.0.0.1:9302&quot;</span>]<br>cluster.<span class="hljs-attr">initial_master_nodes :</span> [<span class="hljs-string">&quot;es-master&quot;</span>]<br>path.<span class="hljs-attr">logs:</span> <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span>logs<br></code></pre></td></tr></table></figure><p><code>docker-compose up</code> 启动即可</p><h2 id="启动错误解决"><a href="#启动错误解决" class="headerlink" title="启动错误解决"></a>启动错误解决</h2><ol><li>docker以挂载配置文件启动elasticsearch的时候会报错误，所以需要给予文件夹权限<br>赋权命令：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">chmod <span class="hljs-number">777</span> master<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node1<span class="hljs-regexp">/data/</span><br>chmod <span class="hljs-number">777</span> node2<span class="hljs-regexp">/data/</span><br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-run</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-run/</url>
    
    <content type="html"><![CDATA[<h2 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h2><p>安装命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">streamsets</span><br><span class="hljs-attribute">docker</span> run --restart <span class="hljs-literal">on</span>-failure -p <span class="hljs-number">18630</span>:<span class="hljs-number">18630</span> -d --name sdc streamsets/datacollector<br><br><span class="hljs-attribute">pgsql</span><br><span class="hljs-attribute">docker</span> run --name postgres -e POSTGRES_PASSWORD=postgres<span class="hljs-number">369</span> -p <span class="hljs-number">5432</span>:<span class="hljs-number">5432</span> -d postgres:<span class="hljs-number">9</span>.<span class="hljs-number">5</span>.<span class="hljs-number">24</span>-alpine<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker-centos7</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/docker-compose/docker-centos7/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装docker"><a href="#centos7安装docker" class="headerlink" title="centos7安装docker"></a>centos7安装docker</h2><p>安装命令：<br><code>yum install -y docker </code></p><p>启动docker<br><code>systemctl start docker</code></p><p>设置docker开机启动<br><code>systemctl enable docker</code></p><p>##安装docker-compose</p><ol><li><p>添加EPEL源</p><p> <code>yum install -y epel-release</code></p></li><li><p>安装python-pip</p><p> <code>yum install -y python-pip</code></p></li><li><p>安装docker-compose</p><p> <code>pip install docker-compose</code></p></li></ol><p>##更换镜像源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs awk">打开文件（没有就新建）<br>vim <span class="hljs-regexp">/etc/</span>docker/daemon.json<br><br>&#123;<br><span class="hljs-string">&quot;registry-mirrors&quot;</span>: [<span class="hljs-string">&quot;http://hub-mirror.c.163.com&quot;</span>]<br>&#125;<br>保存后重启即可<br>service docker restart<br><br>Docker中国区官方镜像<br>https:<span class="hljs-regexp">//</span>registry.docker-cn.com<br><br>网易<br>http:<span class="hljs-regexp">//</span>hub-mirror.c.<span class="hljs-number">163</span>.com<br><br>ustc <br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>中国科技大学<br>https:<span class="hljs-regexp">//</span>docker.mirrors.ustc.edu.cn<br><br>阿里云容器服务(需要先创建容器镜像)<br>https:<span class="hljs-regexp">//</span>cr.console.aliyun.com/<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux常见问题</title>
    <link href="/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/blog/2021/01/04/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/linux/linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<ol><li><p><code>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</code></p><p>解决：<code>sysctl -w vm.max_map_count=262144</code></p><p>重启虚拟机将失效<br>在<code>/etc/sysctl.conf</code>文件最后添加一行<br><code>vm.max_map_count=262144</code>即可永久修改</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>centos7安装MySQL</title>
    <link href="/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/"/>
    <url>/blog/2021/01/03/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/centos7%E5%AE%89%E8%A3%85MySQL/</url>
    
    <content type="html"><![CDATA[<h2 id="centos7安装MySQL"><a href="#centos7安装MySQL" class="headerlink" title="centos7安装MySQL"></a>centos7安装MySQL</h2><ol><li><p>配置YUM源</p><p> <code>wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum localinstall mysql57-community-release-el7-8.noarch.rpm</code></p><p> <code>yum repolist enabled | grep &quot;mysql.*-community.*&quot;</code></p><p> 可以修改<code>vim /etc/yum.repos.d/mysql-community.repo</code>源，改变默认安装的mysql版本。比如要安装5.6版本，将5.7源的enabled=1改成enabled=0。然后再将5.6源的enabled=0改成enabled=1即可。</p></li><li><p>安装MySQL</p><p> <code>yum install mysql-community-server</code></p></li><li><p>启动MySQL服务</p><p> <code>service mysqld start</code></p></li><li><p>开机启动</p><p> <code>systemctl enable mysqld</code></p><p> <code>systemctl daemon-reload</code></p></li><li><p>修改root本地登录密码</p><p> <code>grep &#39;temporary password&#39; /var/log/mysqld.log   ---AkY&gt;ts#9)Dcv</code></p><p> <code>mysql -uroot -p</code></p><p> <code>ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;a1b2c3d4&#39;; </code></p><p> 修改密码策略</p><p> 在<code>/etc/my.cnf</code>文件添加validate_password_policy配置，指定密码策略<br>选择0（LOW），1（MEDIUM），2（STRONG）其中一种，选择2需要提供密码字典文件<br>validate_password_policy=0</p><p> 如果不需要密码策略，添加my.cnf文件中添加如下配置禁用即可：<br><code>validate_password = off</code></p></li><li><p>添加远程登录用户</p><p> 默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户：<br> mysql&gt; <code>GRANT ALL PRIVILEGES ON *.* TO &#39;mysql&#39;@&#39;%&#39; IDENTIFIED BY &#39;mysql123&#39; WITH GRANT OPTION;</code></p><p> 设置root用户远程登录</p><pre><code> use mysql; update user set host = &#39;%&#39; where user = &#39;root&#39;; FLUSH PRIVILEGES;</code></pre></li><li><p>配置默认编码为utf8</p><p> 修改<code>/etc/my.cnf</code>配置文件，在[mysqld]下添加编码配置，如下所示：</p><p> [mysqld]</p><p> character_set_server=utf8</p><p> init_connect=’SET NAMES utf8’</p></li><li><p>不区分大小写</p><p> 在<code>[mysqld]</code>下加上<code>lower_case_table_names=1</code></p></li><li><p>mysql重启服务</p><p> <code>service mysqld restart</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于gitee+hexo搭建个人博客</title>
    <link href="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/"/>
    <url>/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/</url>
    
    <content type="html"><![CDATA[<p>什么是 Hexo？</p><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。  —来自hexo官网<br><code>https://hexo.io/zh-cn/docs/</code></p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>nodejs</li><li>git</li></ul><ol><li><p>安装hexo。 （npm默认镜像源在国外，会有下载失败情况，建议更换taobao镜像源）</p><p> <code>$ npm install -g hexo-cli</code></p></li><li><p>新建个人文件夹，初始化目录为hexo目录。命令如下：</p><pre><code> $ hexo init $ npm install 执行完毕后目录如下： hexo  ├── _config.landscape.yml ├── _config.yml ├── node_modules ├── package-lock.json ├── package.json ├── scaffolds ├── source └── themes</code></pre></li><li><p>启动hexo</p></li></ol><p>在hexo目录下执行 <code>hexo server</code></p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/hexo%E5%90%AF%E5%8A%A8%E5%9B%BE.png" class><p>浏览器访问<strong><a href="http://localhost:4000/">http://localhost:4000</a></strong> 即可</p><h2 id="gitee网站配置"><a href="#gitee网站配置" class="headerlink" title="gitee网站配置"></a>gitee网站配置</h2><ol><li><p>在gitee新建仓库*<strong>.gitee.io</strong> (*号为任意名称)</p></li><li><p>修改<code>_config.yml</code>文件</p><pre><code> 这里只截取部分配置信息 # URL ## If your site is put in a subdirectory, set url as &#39;http://example.com/child&#39; and root as &#39;/child/&#39; url: 后续需要修改  root: 同目录名  deploy:   type: &#39;git&#39;   repo: git仓库地址   如： https://gitee.com/test/test   branch: master   message: blog update</code></pre></li><li><p>安装插件 <code>npm install --save hexo-deployer-git</code></p></li><li><p>执行命令<code>hexo g -d</code> 这里会提示用户名密码，成功后在gitee页面可以看到本地代码已提交到仓库中。</p><img src="/blog/2020/12/31/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/hexo/gitee-pages.png" class></li><li><p>如图操作后点击启动，成功后复制网站地址，访问发现静态资源没有加载。</p></li></ol><ul><li>将配置文件中的url修改为网站地址 例如： <a href="http://ccqi3.gitee.io/test">http://ccqi3.gitee.io/test</a></li><li>root 后是仓库名称如 root: /test/</li></ul><ol start="6"><li>修改完后在hexo目录下再次执行<code>hexo g -d</code> (以后配置有调整或者发布新的文章都用此命令即可)</li><li>在gitee的pages页面里点击更新，再次访问网址发现已经搭建好博客了。</li></ol><h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><ul><li>修改<code>_config.yml</code> 文件中的 <code>post_asset_folder:false</code> 改为 <strong>true</strong><br>这样新建文档时会在文档同级生成同名文件夹，图片资源放入其中。</li><li>安装插件<br><code>npm install https://github.com/7ym0n/hexo-asset-image --save</code></li></ul><p><code>&#123;% asset_img test.jpg This is an test image %&#125;</code><br>test.jpg 就是图片文件名称 后面文字是图片描述</p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p><code>hexo generate</code></p><p><code>hexo server</code></p><p><code>hexo deploy</code></p><p><code>hexo clean</code></p><p><code>hexo new page &quot;type&quot; </code> <strong>type</strong> 如下：</p><table><thead><tr><th>page</th><th>type</th><th>内容</th></tr></thead><tbody><tr><td>tages</td><td>tages</td><td>标签</td></tr><tr><td>categories</td><td>categories</td><td>分类</td></tr><tr><td>archives</td><td>archives</td><td>博客</td></tr><tr><td>about</td><td>about</td><td>关于</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的博客</title>
    <link href="/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    <url>/blog/2020/12/24/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="为什么要写博客"><a href="#为什么要写博客" class="headerlink" title="为什么要写博客"></a>为什么要写博客</h2><ul><li>生活记录</li><li>编程笔记</li></ul>]]></content>
    
    
    <categories>
      
      <category>个人计划</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-06 other</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-06%20other/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-06%20other/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>hadoop 数据存储过程</p><p>client 客户端</p><p>namenode</p><p>datanodes</p><p>InputFormat：将我们输入的数据进行分片(split):</p><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-06%20other/%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%9E%B6%E6%9E%84.png" class title="离线数据处理架构">]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-07 文件系统工作原理漫画</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/</url>
    
    <content type="html"><![CDATA[<img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/1" class><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/2" class><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/3" class><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/4" class><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-07%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%BC%AB%E7%94%BB/5" class>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-05 MapReduce</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/</url>
    
    <content type="html"><![CDATA[<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h3 id="旧的MapReduce的架构："><a href="#旧的MapReduce的架构：" class="headerlink" title="旧的MapReduce的架构："></a>旧的MapReduce的架构：</h3><p><strong>一种分布式的计算方式指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（规约）函数，用来保证所有映射对中的每一个共享相同的键组。</strong></p><p>如图：</p><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-pattern.png" class><p>map: (K1, V1) → list(K2, V2) combine: (K2, list(V2)) → list(K2, V2) reduce: (K2, list(V2)) → list(K3, V3)</p><p>Map输出格式和Reduce输入格式一定是相同的</p><h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><p>MapReduce主要是先读取文件数据，然后进行Map处理，接着Reduce处理，最后把处理结果写到文件中。</p><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-process-overview.png" class><h3 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-process.png" class><h3 id="多节点下的流程"><a href="#多节点下的流程" class="headerlink" title="多节点下的流程"></a>多节点下的流程</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-process-cluster.png" class><h3 id="主要过程"><a href="#主要过程" class="headerlink" title="主要过程"></a>主要过程</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-data-process.png" class><h3 id="Map-Side"><a href="#Map-Side" class="headerlink" title="Map Side"></a>Map Side</h3><h4 id="Record-reader"><a href="#Record-reader" class="headerlink" title="Record reader"></a>Record reader</h4><p>记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。记录读取器的目的是将数据解析成记录，但不分析记录本身。它将数据以键值树的形式传输给mapper，通常是位置信息，值是构成记录的数据存储块，自定义记录不在本文讨论范围之内。</p><h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4><p>在映射器中用户提供的代称为中间对。对于键值的具体定义是慎重的，因为定义对于分布式任务的完成具有重要意义。键决定了数据分类的依据，而值决定了处理器中的分析信息。</p><p>Shuffle and Sort</p><p>reduce任务以随机和排序的步骤开始，此步骤写入输出文件并下载到本地计算机，这些数据采用键进行排序以把等价密钥组合到一起。</p><h4 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h4><p>reduce采用分组数据作为输入，该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当reduce功能完成，就会发送0个或多个键值对。</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>输出格式会转换最终的键值对并写人文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。</p><h3 id="MapReude-读取数据"><a href="#MapReude-读取数据" class="headerlink" title="MapReude - 读取数据"></a>MapReude - 读取数据</h3><p>通过InputFormat决定读取的数据类型，然后拆分成一个个InputSplit，每个InputSplit对应一个Map处理，RecordReader读取InputSplit的内容给Map。</p><h4 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h4><p>决定读取数据的格式，可以是文件或者数据库等。</p><p>功能：</p><ol><li>验证作业输入的正确性，如格式等。</li><li>将输入文件切割成逻辑分片（InputSplit），一个InputSplit将会被分配给一个独立的Map任务。</li><li>提供RecordReader实现，读取InputSplit中“K-V”对供Mapper使用。</li></ol><p>方法：</p><p>List getSplits()：获取由输入文件计算出输入分片(InputSplit)，解决数据或文件分割成片问题。</p><p>RecordReader createRecordReader(): 创建RecordReader，从InputSplit中读取数据，解决读取分片中的数据问题。</p><h4 id="类结构"><a href="#类结构" class="headerlink" title="类结构"></a>类结构</h4><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-inputformat.png" class><ul><li>TextInputFormat: 输入文件中的每一行就是一个记录，Key是这一行的byte offset，而value是这一行的内容</li><li>KeyValueTextInputFormat: 输入文件中每一行就是一个记录，第一个分隔符字符切分每行。在分隔符字符之前的内容为Key，在之后的为Value。分隔符变量通过key.value.separator.in.input.line变量设置，默认为(\t)字符。</li><li>NLineInputFormat: 与TextInputFormat一样，但每个数据块必须保证有且只有Ｎ行，mapred.line.input.format.linespermap属性，默认为１</li><li>SequenceFileInputFormat: 一个用来读取字符流数据的InputFormat，&lt;key,value&gt;为用户自定义的。字符流数据是Hadoop自定义的压缩的二进制数据格式。它用来优化从一个MapReduce任务的输出到另一个MapReduce任务的输入之间的数据传输过程。&lt;/key,value&gt;</li></ul><h3 id="InputSplit"><a href="#InputSplit" class="headerlink" title="InputSplit"></a>InputSplit</h3><p>代表一个个逻辑分片，并没有真正存储数据，只是提供了一个如何将数据分片的方法</p><p>Split内有Location信息，利于数据局部化</p><p>一个InputSplit给一个单独的Map处理</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs groovy"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InputSplit</span> &#123;</span><br>      <span class="hljs-comment">/**</span><br><span class="hljs-comment">       * 获取Split的大小，支持根据size对InputSplit排序.</span><br><span class="hljs-comment">       */</span><br>      <span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">long</span> getLength() <span class="hljs-keyword">throws</span> IOException, InterruptedException;<br><br>      <span class="hljs-comment">/**</span><br><span class="hljs-comment">       * 获取存储该分片的数据所在的节点位置.</span><br><span class="hljs-comment">       */</span><br>      <span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> String[] getLocations() <span class="hljs-keyword">throws</span> IOException, InterruptedException;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="RecordReader"><a href="#RecordReader" class="headerlink" title="RecordReader"></a>RecordReader</h3><p>将InputSplit拆分成一个个&lt;key,value&gt;对给Map处理，也是实际的文件读取分隔对象&lt;/key,value&gt;</p><p>问题</p><h4 id="大量小文件如何处理"><a href="#大量小文件如何处理" class="headerlink" title="大量小文件如何处理"></a>大量小文件如何处理</h4><p>CombineFileInputFormat可以将若干个Split打包成一个，目的是避免过多的Map任务（因为Split的数目决定了Map的数目，大量的Mapper Task创建销毁开销将是巨大的）</p><h4 id="怎么计算split的"><a href="#怎么计算split的" class="headerlink" title="怎么计算split的"></a>怎么计算split的</h4><p>通常一个split就是一个block（FileInputFormat仅仅拆分比block大的文件），这样做的好处是使得Map可以在存储有当前数据的节点上运行本地的任务，而不需要通过网络进行跨节点的任务调度</p><p>通过mapred.min.split.size， mapred.max.split.size, block.size来控制拆分的大小</p><p>如果mapred.min.split.size大于block size，则会将两个block合成到一个split，这样有部分block数据需要通过网络读取</p><p>如果mapred.max.split.size小于block size，则会将一个block拆成多个split，增加了Map任务数（Map对split进行计算并且上报结果，关闭当前计算打开新的split均需要耗费资源）</p><p>先获取文件在HDFS上的路径和Block信息，然后根据splitSize对文件进行切分（ splitSize = computeSplitSize(blockSize, minSize, maxSize) ），默认splitSize 就等于blockSize的默认值（64m）</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">public List&lt;InputSplit&gt; get<span class="hljs-constructor">Splits(JobContext <span class="hljs-params">job</span>)</span> throws IOException &#123;<br>    <span class="hljs-comment">// 首先计算分片的最大和最小值。这两个值将会用来计算分片的大小</span><br>    long minSize = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Math</span>.</span></span>max(get<span class="hljs-constructor">FormatMinSplitSize()</span>, get<span class="hljs-constructor">MinSplitSize(<span class="hljs-params">job</span>)</span>);<br>    long maxSize = get<span class="hljs-constructor">MaxSplitSize(<span class="hljs-params">job</span>)</span>;<br><br>    <span class="hljs-comment">// generate splits</span><br>    List&lt;InputSplit&gt; splits = <span class="hljs-keyword">new</span> ArrayList&lt;InputSplit&gt;<span class="hljs-literal">()</span>;<br>    List&lt;FileStatus&gt; files = <span class="hljs-built_in">list</span><span class="hljs-constructor">Status(<span class="hljs-params">job</span>)</span>;<br>    <span class="hljs-keyword">for</span> (FileStatus file: files) &#123;<br>        Path path = file.get<span class="hljs-constructor">Path()</span>;<br>        long length = file.get<span class="hljs-constructor">Len()</span>;<br>        <span class="hljs-keyword">if</span> (length != <span class="hljs-number">0</span>) &#123;<br>              FileSystem fs = path.get<span class="hljs-constructor">FileSystem(<span class="hljs-params">job</span>.<span class="hljs-params">getConfiguration</span>()</span>);<br>            <span class="hljs-comment">// 获取该文件所有的block信息列表[hostname, offset, length]</span><br>              BlockLocation<span class="hljs-literal">[]</span> blkLocations = fs.get<span class="hljs-constructor">FileBlockLocations(<span class="hljs-params">file</span>, 0, <span class="hljs-params">length</span>)</span>;<br>            <span class="hljs-comment">// 判断文件是否可分割，通常是可分割的，但如果文件是压缩的，将不可分割</span><br>              <span class="hljs-keyword">if</span> (is<span class="hljs-constructor">Splitable(<span class="hljs-params">job</span>, <span class="hljs-params">path</span>)</span>) &#123;<br>                long blockSize = file.get<span class="hljs-constructor">BlockSize()</span>;<br>                <span class="hljs-comment">// 计算分片大小</span><br>                <span class="hljs-comment">// 即 Math.max(minSize, Math.min(maxSize, blockSize));</span><br>                long splitSize = compute<span class="hljs-constructor">SplitSize(<span class="hljs-params">blockSize</span>, <span class="hljs-params">minSize</span>, <span class="hljs-params">maxSize</span>)</span>;<br><br>                long bytesRemaining = length;<br>                <span class="hljs-comment">// 循环分片。</span><br>                <span class="hljs-comment">// 当剩余数据与分片大小比值大于Split_Slop时，继续分片， 小于等于时，停止分片</span><br>                <span class="hljs-keyword">while</span> (((double) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;<br>                      <span class="hljs-built_in">int</span> blkIndex = get<span class="hljs-constructor">BlockIndex(<span class="hljs-params">blkLocations</span>, <span class="hljs-params">length</span>-<span class="hljs-params">bytesRemaining</span>)</span>;<br>                      splits.add(make<span class="hljs-constructor">Split(<span class="hljs-params">path</span>, <span class="hljs-params">length</span>-<span class="hljs-params">bytesRemaining</span>, <span class="hljs-params">splitSize</span>, <span class="hljs-params">blkLocations</span>[<span class="hljs-params">blkIndex</span>].<span class="hljs-params">getHosts</span>()</span>));<br>                      bytesRemaining -= splitSize;<br>                &#125;<br>                <span class="hljs-comment">// 处理余下的数据</span><br>                <span class="hljs-keyword">if</span> (bytesRemaining != <span class="hljs-number">0</span>) &#123;<br>                    splits.add(make<span class="hljs-constructor">Split(<span class="hljs-params">path</span>, <span class="hljs-params">length</span>-<span class="hljs-params">bytesRemaining</span>, <span class="hljs-params">bytesRemaining</span>, <span class="hljs-params">blkLocations</span>[<span class="hljs-params">blkLocations</span>.<span class="hljs-params">length</span>-1].<span class="hljs-params">getHosts</span>()</span>));<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">// 不可split，整块返回</span><br>                splits.add(make<span class="hljs-constructor">Split(<span class="hljs-params">path</span>, 0, <span class="hljs-params">length</span>, <span class="hljs-params">blkLocations</span>[0].<span class="hljs-params">getHosts</span>()</span>));<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 对于长度为0的文件，创建空Hosts列表，返回</span><br>            splits.add(make<span class="hljs-constructor">Split(<span class="hljs-params">path</span>, 0, <span class="hljs-params">length</span>, <span class="hljs-params">new</span> String[0])</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 设置输入文件数量</span><br>    job.get<span class="hljs-constructor">Configuration()</span>.set<span class="hljs-constructor">Long(NUM_INPUT_FILES, <span class="hljs-params">files</span>.<span class="hljs-params">size</span>()</span>);<br>    <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">LOG</span>.</span></span>debug(<span class="hljs-string">&quot;Total # of splits: &quot;</span> + splits.size<span class="hljs-literal">()</span>);<br>    return splits;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="分片间的数据如何处理"><a href="#分片间的数据如何处理" class="headerlink" title="分片间的数据如何处理"></a>分片间的数据如何处理</h2><p>split是根据文件大小分割的，而一般处理是根据分隔符进行分割的，这样势必存在一条记录横跨两个split</p><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-split.png" class><p>解决办法是只要不是第一个split，都会远程读取一条记录。不是第一个split的都忽略到第一条记录</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-keyword">public</span> class LineRecordReader extends RecordReader&lt;LongWritable, Text&gt; &#123;<br>    <span class="hljs-keyword">private</span> CompressionCodecFactory compressionCodecs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> start;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> pos;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> end;<br>    <span class="hljs-keyword">private</span> LineReader in;<br>    <span class="hljs-keyword">private</span> <span class="hljs-built_in">int</span> maxLineLength;<br>    <span class="hljs-keyword">private</span> LongWritable <span class="hljs-built_in">key</span> = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">private</span> Text value = <span class="hljs-keyword">null</span>;<br><br>    <span class="hljs-comment">// initialize函数即对LineRecordReader的一个初始化</span><br>    <span class="hljs-comment">// 主要是计算分片的始末位置，打开输入流以供读取K-V对，处理分片经过压缩的情况等</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> initialize(InputSplit genericSplit, TaskAttemptContext context) <span class="hljs-keyword">throws</span> IOException &#123;<br>        FileSplit <span class="hljs-built_in">split</span> = (FileSplit) genericSplit;<br>        Configuration job = context.getConfiguration();<br>        <span class="hljs-keyword">this</span>.maxLineLength = job.getInt(<span class="hljs-string">&quot;mapred.linerecordreader.maxlength&quot;</span>, Integer.MAX_VALUE);<br>        start = <span class="hljs-built_in">split</span>.getStart();<br>        end = start + <span class="hljs-built_in">split</span>.getLength();<br>        <span class="hljs-keyword">final</span> Path file = <span class="hljs-built_in">split</span>.getPath();<br>        compressionCodecs = <span class="hljs-keyword">new</span> CompressionCodecFactory(job);<br>        <span class="hljs-keyword">final</span> CompressionCodec codec = compressionCodecs.getCodec(file);<br><br>        <span class="hljs-comment">// 打开文件，并定位到分片读取的起始位置</span><br>        FileSystem fs = file.getFileSystem(job);<br>        FSDataInputStream fileIn = fs.<span class="hljs-built_in">open</span>(<span class="hljs-built_in">split</span>.getPath());<br><br>        <span class="hljs-built_in">boolean</span> skipFirstLine = <span class="hljs-keyword">false</span>;<br>        <span class="hljs-keyword">if</span> (codec != <span class="hljs-keyword">null</span>) &#123;<br>            <span class="hljs-comment">// 文件是压缩文件的话，直接打开文件</span><br>            in = <span class="hljs-keyword">new</span> LineReader(codec.createInputStream(fileIn), job);<br>            end = Long.MAX_VALUE;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 只要不是第一个split，则忽略本split的第一行数据</span><br>            <span class="hljs-keyword">if</span> (start != <span class="hljs-number">0</span>) &#123;<br>                skipFirstLine = <span class="hljs-keyword">true</span>;<br>                --start;<br>                <span class="hljs-comment">// 定位到偏移位置，下次读取就会从偏移位置开始</span><br>                fileIn.seek(start);<br>            &#125;<br>            in = <span class="hljs-keyword">new</span> LineReader(fileIn, job);<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (skipFirstLine) &#123;<br>            <span class="hljs-comment">// 忽略第一行数据，重新定位start</span><br>            start += in.readLine(<span class="hljs-keyword">new</span> Text(), <span class="hljs-number">0</span>, (<span class="hljs-built_in">int</span>) Math.<span class="hljs-built_in">min</span>((<span class="hljs-keyword">long</span>) Integer.MAX_VALUE, end - start));<br>        &#125;<br>        <span class="hljs-keyword">this</span>.pos = start;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">boolean</span> nextKeyValue() <span class="hljs-keyword">throws</span> IOException &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">key</span> == <span class="hljs-keyword">null</span>) &#123;<br>            <span class="hljs-built_in">key</span> = <span class="hljs-keyword">new</span> LongWritable();<br>        &#125;<br>        <span class="hljs-built_in">key</span>.<span class="hljs-built_in">set</span>(pos);<span class="hljs-comment">// key即为偏移量</span><br>        <span class="hljs-keyword">if</span> (value == <span class="hljs-keyword">null</span>) &#123;<br>            value = <span class="hljs-keyword">new</span> Text();<br>        &#125;<br>        <span class="hljs-built_in">int</span> newSize = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (pos &lt; end) &#123;<br>            newSize = in.readLine(value, maxLineLength,    Math.<span class="hljs-built_in">max</span>((<span class="hljs-built_in">int</span>) Math.<span class="hljs-built_in">min</span>(Integer.MAX_VALUE, end - pos), maxLineLength));<br>            <span class="hljs-comment">// 读取的数据长度为0，则说明已读完</span><br>            <span class="hljs-keyword">if</span> (newSize == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            pos += newSize;<br>            <span class="hljs-comment">// 读取的数据长度小于最大行长度，也说明已读取完毕</span><br>            <span class="hljs-keyword">if</span> (newSize &lt; maxLineLength) &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-comment">// 执行到此处，说明该行数据没读完，继续读入</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> (newSize == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-built_in">key</span> = <span class="hljs-keyword">null</span>;<br>            value = <span class="hljs-keyword">null</span>;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="MapReduce-Mapper"><a href="#MapReduce-Mapper" class="headerlink" title="MapReduce - Mapper"></a>MapReduce - Mapper</h2><p>主要是读取InputSplit的每一个Key,Value对并进行处理</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-symbol">Mapper</span>&lt;<span class="hljs-symbol">KEYIN, <span class="hljs-symbol">VALUEIN</span>, <span class="hljs-symbol">KEYOUT</span>, <span class="hljs-symbol">VALUEOUT</span></span>&gt; &#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 预处理，仅在map task启动时运行一次</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-built_in">void</span> setup(Context context) throws  IOException, InterruptedException &#123;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 对于InputSplit中的每一对&lt;key, value&gt;都会运行一次</span><br><span class="hljs-comment">     */</span><br>    @SuppressWarnings(<span class="hljs-string">&quot;unchecked&quot;</span>)<br>    <span class="hljs-keyword">protected</span> <span class="hljs-built_in">void</span> map(KEYIN key, VALUEIN value, Context context) throws IOException, InterruptedException &#123;<br>        context.write((KEYOUT) key, (VALUEOUT) value);<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 扫尾工作，比如关闭流等</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-built_in">void</span> cleanup(Context context) throws IOException, InterruptedException &#123;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * map task的驱动器</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> run(Context context) throws IOException, InterruptedException &#123;<br>        setup(context);<br>        <span class="hljs-keyword">while</span> (context.nextKeyValue()) &#123;<br>            map(context.getCurrentKey(), context.getCurrentValue(), context);<br>        &#125;<br>        cleanup(context);<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-symbol">MapContext</span>&lt;<span class="hljs-symbol">KEYIN, <span class="hljs-symbol">VALUEIN</span>, <span class="hljs-symbol">KEYOUT</span>, <span class="hljs-symbol">VALUEOUT</span></span>&gt; <span class="hljs-symbol">extends</span> <span class="hljs-symbol">TaskInputOutputContext</span>&lt;<span class="hljs-symbol">KEYIN, <span class="hljs-symbol">VALUEIN</span>, <span class="hljs-symbol">KEYOUT</span>, <span class="hljs-symbol">VALUEOUT</span></span>&gt; &#123;<br>    <span class="hljs-keyword">private</span> RecordReader&lt;KEYIN, VALUEIN&gt; reader;<br>    <span class="hljs-keyword">private</span> InputSplit split;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Get the input split for this map.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> InputSplit getInputSplit() &#123;<br>        <span class="hljs-keyword">return</span> split;<br>    &#125;<br><br>    @Override<br>    <span class="hljs-keyword">public</span> KEYIN getCurrentKey() throws IOException, InterruptedException &#123;<br>        <span class="hljs-keyword">return</span> reader.getCurrentKey();<br>    &#125;<br><br>    @Override<br>    <span class="hljs-keyword">public</span> VALUEIN getCurrentValue() throws IOException, InterruptedException &#123;<br>        <span class="hljs-keyword">return</span> reader.getCurrentValue();<br>    &#125;<br><br>    @Override<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">bool</span>ean nextKeyValue() throws IOException, InterruptedException &#123;<br>        <span class="hljs-keyword">return</span> reader.nextKeyValue();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="MapReduce-Shuffle"><a href="#MapReduce-Shuffle" class="headerlink" title="MapReduce - Shuffle"></a>MapReduce - Shuffle</h2><p>对Map的结果进行排序并传输到Reduce进行处理Map的结果并不是直接存放在硬盘，而是利用缓存做一些与排序处理Map会调用Combiner，压缩，按key进行分区，排序等。尽量减少结果的大小每个Map完成后都会通知Task，然后Reduce就可以进行处理。</p><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-05%20MapReduce/mapreduce-process.png" class><h4 id="Map端"><a href="#Map端" class="headerlink" title="Map端"></a>Map端</h4><ol><li>当Map程序开始产生结果的时候，并不是直接写到文件的，而是利用缓存做一些排序方面的预处理操作</li><li>每个Map任务都有一个循环内存缓冲区（默认100MB），当缓存的内容达到80%时，后台线程开始将内容写到文件，此时Map任务可以继续输出结果，但如果缓冲区满了，Map任务则需要等待</li><li>写文件使用round-robin方式。在写入文件之前，先将数据按照Reduce进行分区。对于每一个分区，都会在内存中根据key进行排序，如果配置了Combiner，则排序后执行Combiner（Combine之后可以减少写入文件和传输的数据）</li><li>每次结果达到缓冲区的阀值时，都会创建一个文件，在Map结束时，可能会产生大量的文件。在Map完成前，会将这些文件进行合并和排序。如果文件的数量超过3个，则合并后会再次运行Combiner（1、2个文件就没有必要了）</li><li>如果配置了压缩，则最终写入的文件会先进行压缩，这样可以减少写入和传输的数据</li><li>一旦Map完成，则通知任务管理器，此时Reduce就可以开始复制结果数据<h4 id="Reduce端"><a href="#Reduce端" class="headerlink" title="Reduce端"></a>Reduce端</h4></li><li>Map的结果文件都存放到运行Map任务的机器的本地硬盘中</li><li>如果Map的结果很少，则直接放到内存，否则写入文件中</li><li>同时后台线程将这些文件进行合并和排序到一个更大的文件中（如果文件是压缩的，则需要先解压）</li><li>当所有的Map结果都被复制和合并后，就会调用Reduce方法<br>Reduce结果会写入到HDFS中<h4 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h4></li><li>一般的原则是给shuffle分配尽可能多的内存，但前提是要保证Map、Reduce任务有足够的内存</li><li>对于Map，主要就是避免把文件写入磁盘，例如使用Combiner，增大io.sort.mb的值</li><li>对于Reduce，主要是把Map的结果尽可能地保存到内存中，同样也是要避免把中间结果写入磁盘。默认情况下，所有的内存都是分配给Reduce方法的，如果Reduce方法不怎么消耗内存，可以mapred.inmem.merge.threshold设成0，mapred.job.reduce.input.buffer.percent设成1.0</li><li>在任务监控中可通过Spilled records counter来监控写入磁盘的数，但这个值是包括map和reduce的</li><li>对于IO方面，可以Map的结果可以使用压缩，同时增大buffer size（io.file.buffer.size，默认4kb）<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><table><thead><tr><th>属性</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>io.sort.mb</td><td>100</td><td>映射输出分类时所使用缓冲区的大小.</td></tr><tr><td>io.sort.record.percent</td><td>0.05</td><td>剩余空间用于映射输出自身记录.在1.X发布后去除此属性.随机代码用于使用映射所有内存并记录信息.</td></tr><tr><td>io.sort.spill.percent</td><td>0.80</td><td>针对映射输出内存缓冲和记录索引的阈值使用比例.</td></tr><tr><td>io.sort.factor</td><td>10</td><td>文件分类时合并流的最大数量。此属性也用于reduce。通常把数字设为100.</td></tr><tr><td>min.num.spills.for.combine</td><td>3</td><td>组合运行所需最小溢出文件数目.</td></tr><tr><td>mapred.compress.map.output</td><td>false</td><td>压缩映射输出.</td></tr><tr><td>mapred.map.output.compression.codec</td><td>DefaultCodec</td><td>映射输出所需的压缩解编码器.</td></tr><tr><td>mapred.reduce.parallel.copies</td><td>5</td><td>用于向reducer传送映射输出的线程数目.</td></tr><tr><td>mapred.reduce.copy.backoff</td><td>300</td><td>时间的最大数量，以秒为单位，这段时间内若reducer失败则会反复尝试传输</td></tr><tr><td>io.sort.factor</td><td>10</td><td>组合运行所需最大溢出文件数目.</td></tr><tr><td>mapred.job.shuffle.input.buffer.percent</td><td>0.70</td><td>随机复制阶段映射输出缓冲器的堆栈大小比例</td></tr><tr><td>mapred.job.shuffle.merge.percent</td><td>0.66</td><td>用于启动合并输出进程和磁盘传输的映射输出缓冲器的阀值使用比例</td></tr><tr><td>mapred.inmem.merge.threshold</td><td>1000</td><td>用于启动合并输出和磁盘传输进程的映射输出的阀值数目。小于等于0意味着没有门槛，而溢出行为由 mapred.job.shuffle.merge.percent单独管理.</td></tr><tr><td>mapred.job.reduce.input.buffer.percent</td><td>0.0</td><td>用于减少内存映射输出的堆栈大小比例，内存中映射大小不得超出此值。若reducer需要较少内存则可以提高该值.</td></tr></tbody></table></li></ol><h2 id="MapReduce-编程"><a href="#MapReduce-编程" class="headerlink" title="MapReduce - 编程"></a>MapReduce - 编程</h2><p>处理 </p><ol><li>select：直接分析输入数据，取出需要的字段数据即可</li><li>where: 也是对输入数据处理的过程中进行处理，判断是否需要该数据</li><li>aggregation:min, max, sum</li><li>group by: 通过Reducer实现</li><li>sort</li><li>join: map join, reduce join</li></ol><p>优点：海量数据里离线处理，易开发，易运行</p><p>缺点：实时流式计算</p><p>(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</p><p>核心概念：</p><p>split：交由MapReduce作业来处理的数据块，是MapReduce中最小的计算单元。</p><p>HDFS：blocksize 是hdfs中最小的存储单元， 128M</p><p>默认情况下：他们两是一一对应的，可以手工设置（不建议）</p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-04 yarn</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/</url>
    
    <content type="html"><![CDATA[<h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><h3 id="旧的MapReduce的架构："><a href="#旧的MapReduce的架构：" class="headerlink" title="旧的MapReduce的架构："></a>旧的MapReduce的架构：</h3><ul><li><p>JobTracker：负责资源管理，跟踪资源消耗和可用性，作业生命周期管理（调度作业任务，跟踪进度，为任务提供容错）</p></li><li><p>TaskTracker：加载或关闭任务，定时报告任务状态。</p></li><li><p>此架构会有以下问题：</p><ol><li>JobTracker是MapReduce的集中处理点，存在单点故障。</li><li>JobTracker完成了太多的任务，造成了过多的资源消耗，当MapReduce Job非常多的时候，会造成很大的内存开销。这也是业界普遍总结出老版本Hadoop的MapReduce只能支持4000节点的主机上限。</li><li>在TaskTracker端，以map/reduce task的数目作为资源的表示过于简单，没有考虑到cpu/内存的占用情况，如果两个大内存消耗的task被调度的一起，很容易出现OOM。</li><li>在TaskTracker端，把资源强制划分为map task slot 和 reduce task slot，如果当系统中只有map task或者只有reduce task的时候，会造成资源浪费，也就是集群资源的利用问题。</li><li>总结就是单点问题和资源利用率问题。</li></ol></li></ul><hr><h3 id="yarn的架构："><a href="#yarn的架构：" class="headerlink" title="yarn的架构："></a>yarn的架构：</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" class title="yarn架构图"><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E6%9E%B6%E6%9E%84%E5%9B%BE2.jpg" class title="yarn架构图"><p>YARN就是把JobTracker的职责拆分，将资源管理和任务调度监控拆分成独立的进程，一个全局的资源管理和一个每个作业的管理（ApplicationMaster）ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行。</p><ul><li>ResourceManager : RM  – 全局资源管理和任务调度<ul><li>整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度。</li><li>处理客户端的请求：提交一个作业，杀死一个作业</li><li>监控NM，一旦NM挂了，那么改NM上运行的任务需要告诉AM来如何进行处理</li></ul></li><li>NodeManager: NM – 单个节点的资源管理和监控<ul><li>整个集群中有多个，负责自己本身节点资源管理和使用</li><li>定时向RM汇报本节点的资源使用情况</li><li>接受并处理来自RM的各种命令：启动Container</li><li>处理来自AM的命令</li><li>每个节点的资源管理</li></ul></li><li>ApplicationMaster: AM – 单个作业的资源管理和任务监控<ul><li>每个应用程序对应一个：MR、Spark，负责应用程序的管理</li><li>为应用程序向RM申请资源（core、memory），分配给内部task</li><li>需要与NM通信： 启动/停止task，task是运行在container里面，AM也是运行在Container里面的</li></ul></li><li>Container  – 资源申请的单位和任务运行的容器<ul><li>封装了CPU、Memory等资源的一个容器</li><li>是一个任务运行环境的抽象</li></ul></li><li>Client<ul><li>提交作业</li><li>查询作业的运行进度</li><li>杀死作业</li></ul></li></ul><hr><h3 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94.jpg" class title="架构对比"><h2 id="YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。"><a href="#YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。" class="headerlink" title="YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。"></a><strong>YARN架构下形成了一个通用的资源管理平台和一个通用的应用计算平台。避免了旧架构的单点问题和资源利用率的问题，同时也让在其上运行的应用不局限于MapReduce形式。</strong></h2><h3 id="YARN的基本流程"><a href="#YARN的基本流程" class="headerlink" title="YARN的基本流程"></a>YARN的基本流程</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/yarn%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B2.jpg" class title="架构对比"><ol><li>Job submission<ol><li> 从ResourceManager中获取一个Application ID检查作业输出配置，计算输入分片拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行。</li></ol></li><li>Job initialization<ol><li> ResourceManager将作业递交给Scheduler（有很多算法，一般根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process 并交给NodeManager。</li><li>管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的调度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master ，还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行。</li></ol></li><li>Task assignment<ol><li>ApplicationMaster 向Resource Manager 申请资源（一个个的Container，指定任务分配资源要求）一般是根据data locality来分配资源。</li></ol></li><li>Task execution<ol><li>ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container从HDFS中读取任务所需资源（job  jar ，配置文件等）然后执行该任务。</li></ol></li><li>Progress and status update<ol><li>定时将任务的进度和状态报告给ApplicationMaster Client 定时向ApplicationMaster获取整个任务的进度和状态。</li></ol></li><li>Job completion<ol><li>Client 定时检查整个作业是否完成，作业完成后，会清空临时文件，目录。</li></ol></li></ol><hr><h3 id="YARN-ResourceManager"><a href="#YARN-ResourceManager" class="headerlink" title="YARN - ResourceManager"></a>YARN - ResourceManager</h3><p><strong>负责全局的资源管理和任务调度，把整个集群当成计算资源池，只关注分配，不管应用，且不负责容错。</strong></p><h4 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h4><ol><li>以前资源是每个节点分成一个个的Map slot和Reduce slot，现在是一个个Container，每个Container可以根据需要运行ApplicationMaster、map、Reduce或任意的程序。</li><li>以前的资源分配是静态的，目前是动态的，资源利用率更高。</li><li>Container是资源申请的单位，一个资源申请格式：<code>&lt;resource-name, priority, resource-requirement, number-of-containers&gt;</code>, resource-name：主机名、机架名或*（代表任意机器）, resource-requirement：目前只支持CPU和内存</li><li>用户提交作业到ResourceManger ，然后在某个NodeManager上分配一个Container来运行ApplicationMaster，ApplicationMaster再根据自身程序需要向ResourceManager申请资源。</li><li>YARN有一套Container的生命周期管理机制，而ApplicationMaster和其Container之间的管理是应用程序自己定义的。</li></ol><h4 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h4><ol><li>只关注资源的使用情况，根据需求合理分配资源。</li><li>Schedule可以根据申请的需要，在特定的机器上申请特定的资源（ApplicationMaster负责申请资源时的数据本地化的考虑，ResourceManager将尽量满足其申请需求，在指定的机器上分配Container，从而减少数据移动）。<h4 id="内部结构"><a href="#内部结构" class="headerlink" title="内部结构"></a>内部结构</h4><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-04%20yarn/ResourceManager.jpg" class></li></ol><ul><li>Client Service: 应用提交、终止、输出信息（应用、队列、集群等的状态信息）。</li><li>Adaminstration Service: 队列、节点、Client权限管理。</li><li>ApplicationMasterService: 注册、终止ApplicationMaster, 获取ApplicationMaster的资源申请或取消的请求，并将其异步地传给Scheduler, 单线程处理。</li><li>ApplicationMaster Liveliness Monitor: 接收ApplicationMaster的心跳消息，如果某个ApplicationMaster在一定时间内没有发送心跳，则被任务失效，其资源将会被回收，然后ResourceManager会重新分配一个ApplicationMaster运行该应用（默认尝试2次）。</li><li>Resource Tracker Service: 注册节点, 接收各注册节点的心跳消息。</li><li>NodeManagers Liveliness Monitor: 监控每个节点的心跳消息，如果长时间没有收到心跳消息，则认为该节点无效, 同时所有在该节点上的Container都标记成无效，也不会调度任务到该节点运行。</li><li>ApplicationManager: 管理应用程序，记录和管理已完成的应用。</li><li>ApplicationMaster Launcher: 一个应用提交后，负责与NodeManager交互，分配Container并加载ApplicationMaster，也负责终止或销毁。</li><li>YarnScheduler: 资源调度分配， 有FIFO(with Priority)，Fair，Capacity方式。</li><li>ContainerAllocationExpirer: 管理已分配但没有启用的Container，超过一定时间则将其回收。</li></ul><hr><h3 id="YARN-NodeManager"><a href="#YARN-NodeManager" class="headerlink" title="YARN - NodeManager"></a>YARN - NodeManager</h3><p>Node节点下的Container管理</p><ol><li>启动时向ResourceManager注册并定时发送心跳信息，等待ResourceManager的指令。</li><li>监控Container的运行，维护Container的生命周期，监控Container的资源使用情况。</li><li>启动或停止Container，管理任务运行时的依赖包（根据ApplicationMaster的需要，启动Container之前将需要的程序及其依赖包、配置文件等拷贝到本地）。</li></ol><ul><li><p>NodeStatusUpdater: 启动向ResourceManager注册，报告该节点的可用资源情况，通信的端口和后续状态的维护。</p></li><li><p>ContainerManager: 接收RPC请求（启动、停止），资源本地化（下载应用需要的资源到本地，根据需要共享这些资源）。</p><pre><code>PUBLIC: /filecachePRIVATE: /usercache//filecacheAPPLICATION: /usercache//appcache//（在程序完成后会被删除）</code></pre></li><li><p>ContainersLauncher: 加载或终止Container。</p></li><li><p>ContainerMonitor: 监控Container的运行和资源使用情况。</p></li><li><p>ContainerExecutor: 和底层操作系统交互，加载要运行的程序。</p></li></ul><hr><h3 id="YARN-ApplicationMaster"><a href="#YARN-ApplicationMaster" class="headerlink" title="YARN - ApplicationMaster"></a>YARN - ApplicationMaster</h3><p>单个作业的资源管理和任务监控</p><p>具体功能描述：</p><ol><li>计算应用的资源需求，资源可以是静态或动态计算的，静态的一般是Client申请时就指定了，动态则需要ApplicationMaster根据应用的运行状态来决定。</li><li>根据数据来申请对应位置的资源（Data Locality）。</li><li>向ResourceManger申请资源，与NodeManger交互进行程序的运行和监控，监控申请的资源的使用情况，监控作业调度。</li><li>跟踪任务状态和调度，定时向ResourceManger发送心跳信息，报告资源的使用情况和应用的进度信息。</li><li>负责本作业内的任务的容错。</li></ol><p>ApplicationMaster可以是用任何语言编写的程序，它和ResourceManger和NodeManager之间通过protocolBuf交互，以前是一个全局的JobTracker负责的，现在每个左右都一个，可伸缩性更强，至少不会因为作业太多，造成JobTracker瓶颈。同时将作业的逻辑放到一个独立的ApplicationMaster中，使得灵活性更高，每个作业都可以由自己的处理方式，不用绑定到MapReduce的处理模式上。</p><h4 id="如何计算资源需求："><a href="#如何计算资源需求：" class="headerlink" title="如何计算资源需求："></a>如何计算资源需求：</h4><p>一般的MapReduce是根据block数量来定Map和Reduce的计算数量，然后一般的Map或Reduce就占用一个Container。</p><h4 id="如何发现数据的本地化："><a href="#如何发现数据的本地化：" class="headerlink" title="如何发现数据的本地化："></a>如何发现数据的本地化：</h4><h2 id="数据本地化是通过HDFS的block分片信息获取的"><a href="#数据本地化是通过HDFS的block分片信息获取的" class="headerlink" title="数据本地化是通过HDFS的block分片信息获取的"></a>数据本地化是通过HDFS的block分片信息获取的</h2><h3 id="YARN-Container"><a href="#YARN-Container" class="headerlink" title="YARN - Container"></a>YARN - Container</h3><ol><li>基本的资源单位（cpu、内存等）。</li><li>Container可以加载任何程序，而且不限于java。</li><li>一个Node可以包含多个Container，也可以是一个大的Container。</li><li>ApplicationMaster可以根据需要，动态申请和释放Container。</li></ol><hr><h3 id="YARN-Failover"><a href="#YARN-Failover" class="headerlink" title="YARN - Failover"></a>YARN - Failover</h3><p>失败类型</p><ol><li>程序问题。</li><li>进程崩溃。</li><li>硬件问题。</li></ol><p>失败处理</p><p>任务失败</p><ol><li>运行时异常或者JVM退出都会报告给ApplicationMaster。</li><li>通过心跳来检查挂住的任务(timeout)，会检查多次（可配置）才判断该任务是否失效。</li><li>一个作业的任务失败率超过配置，则认为该作业失败。</li><li>失败的任务或作业都会有ApplicationMaster重新运行。<h4 id="ApplicationMaster失败"><a href="#ApplicationMaster失败" class="headerlink" title="ApplicationMaster失败"></a>ApplicationMaster失败</h4></li><li>ApplicationMaster定时发送心跳信号到ResourceManager，通常一旦ApplicationMaster失败，则认为失败，但也可以通过配置多次后才失败</li><li>一旦ApplicationMaster失败，ResourceManager会启动一个新的ApplicationMaster</li><li>新的ApplicationMaster负责恢复之前错误的ApplicationMaster的状(yarn.app.mapreduce.am.job.recovery.enable=true)，这一步是通过将应用运行状态保存到共享的存储上来实现的，ResourceManager不会负责任务状态的保存和恢复</li><li>Client也会定时向ApplicationMaster查询进度和状态，一旦发现其失败，则向ResouceManager询问新的ApplicationMaster<h4 id="NodeManager失败"><a href="#NodeManager失败" class="headerlink" title="NodeManager失败"></a>NodeManager失败</h4></li><li>NodeManager定时发送心跳到ResourceManager，如果超过一段时间没有收到心跳消息，ResourceManager就会将其移除</li><li>任何运行在该NodeManager上的任务和ApplicationMaster都会在其他NodeManager上进行恢复</li><li>如果某个NodeManager失败的次数太多，ApplicationMaster会将其加入黑名单（ResourceManager没有），任务调度时不在其上运行任务<h4 id="ResourceManager失败"><a href="#ResourceManager失败" class="headerlink" title="ResourceManager失败"></a>ResourceManager失败</h4></li><li>通过checkpoint机制，定时将其状态保存到磁盘，然后失败的时候，重新运行</li><li>通过zookeeper同步状态和实现透明的HA</li></ol><p><strong>可以看出，一般的错误处理都是由当前模块的父模块进行监控（心跳）和恢复。而最顶端的模块则通过定时保存、同步状态和zookeeper来ֹ实现HA</strong></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-03 hdfs</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/</url>
    
    <content type="html"><![CDATA[<h2 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h2><p>介绍： hdfs是Hadoop实现的分布式文件系统</p><h3 id="HDFS架构："><a href="#HDFS架构：" class="headerlink" title="HDFS架构："></a>HDFS架构：</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hdfs架构图"><p>1个Master（NameNode/NN） 带 N个Slaves（DataNode/DN）</p><p>blocksize：128M</p><p>NN：负责客户端请求的响应，负责元数据（文件的名称、副本系数、block存放的DN）的管理</p><p>DN：存储用户的文件对应的数据块，要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况。</p><ul><li>NameNode<ol><li>存储文件的metadata，运行时所有数据都保存到内存，整个hdfs可存储的文件数受限于NameNode的内存大小。</li><li>一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果大量小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理的开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件速度。因此，Hadoop建议存储大文件。</li><li>数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode和DateNode的相关信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）</li><li>NameNode失效则整个hdfs都会失效，所以要保证NameNode的可用性。</li></ol></li><li>DataNode<ol><li> 保存具体的block数据。</li><li> 负责数据的读写操作和复杂操作。</li><li>DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息。</li><li>DataNode之间会互相进行通信，复制数据块，保证数据的冗余性。</li></ol></li><li>Block数据块<ol><li>基本存储单位，默认为128M（配置大的块主要是因为a.减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间。b.减少管理块的数据开销，每个块需要在NameNode上有对应的记录。c.对数据块进行读写，减少建立网络的连接成本。）</li><li>一个大文件会被拆成多个块，然后存储于不同的机器。如果一个文件少于block的大小，那么实际占用的空间为文件的大小。</li><li>基本的读写资源，类似于磁盘的页，每次都是读写一个块。</li><li>每个块都是被复制到多台机器，默认是3份。</li></ol></li><li>Secondary NameNode<ol><li>定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的数据传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手动将其设置为主机。</li></ol></li></ul><hr><h3 id="HDFS-写文件"><a href="#HDFS-写文件" class="headerlink" title="HDFS-写文件"></a>HDFS-写文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-write.png" class><ol><li><p>客户端将文件写入本地磁盘的Hdfs Client文件中。</p></li><li><p>当临时文件大小达到一个block的时候，Hdfs Client通知NameNode，申请写入文件。</p></li><li><p>NameNode在Hdfs的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端。</p></li><li><p>客户端收到这些信息后，将临时文件写入DataNodes。</p><ol><li>客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输）。</li><li> 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode。</li><li>以此类推到最后一个DataNode，数据在DataNode之间是通过pipline的方式进行复制的。</li><li>后面的DataNode接受完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端。</li><li>当客户端收到整个block的确认后，会向NameNode发送一个最终的确认信息。</li><li>如果写入某个DataNode失败，数据会继续写人其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性。</li><li>每个block都会有一个校验码，并存放在独立的文件中，以便读的时候来验证其完整性。</li></ol></li><li><p>文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode挂掉，那文件也就丢失了。只保证了数据信息写到NameNode上，并不能保证数据已经被写到了DataNode中）</p><h3 id="Rack-aware（机架感知）"><a href="#Rack-aware（机架感知）" class="headerlink" title="Rack aware（机架感知）"></a>Rack aware（机架感知）</h3><p> 通过配置文件指定机架名和DNS的对应关系</p><p> 假设复制参数是3，在写入文件时，会在本地的机架保存一份数据，然后在另外一个机架内保存两份数据（同机架内的传输速度快，从而提高性能）</p><p> 整个HDFS的集群，最好是负载平衡的，这样才能尽量利用集群的优势</p></li></ol><hr><h3 id="HDFS-读文件"><a href="#HDFS-读文件" class="headerlink" title="HDFS-读文件"></a>HDFS-读文件</h3><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-03%20hdfs/hdfs-read.png" class><ol><li>客户端向NameNode发送读取请求。</li><li>NameNode返回文件所有Block和这些block所在的DataNodes(包括复制节点)</li><li>客户端直接从DataNode中读取数据，如果该DataNode读取失败(DataNode失效或校验码不对)，则从复制节点中读取(如果读取的数据就在本机，则直接读取，否则通过网络读取)。</li></ol><hr><h3 id="HDFS-可靠性"><a href="#HDFS-可靠性" class="headerlink" title="HDFS-可靠性"></a>HDFS-可靠性</h3><ul><li>冗余副本策略<ul><li>可以在hdfs-site.xml中设置复制因子指定副本数量。<br>所有数据块都可副本。</li><li>DataNode启动时，遍历本地文件系统，产生一份HDFS数据块和本地文件对应关系列表(blockreport)汇报给NameNode。</li></ul></li><li>机架策略<ul><li>HDFS的“机架感知”，通过节点之间发送一个数据包，来判断他们是否在同一个机架。</li><li>一般本机架放一个副本，在其他机架再存放一个副本，这样可以防止机架失效时丢失数据，也可以提高带宽利用率。</li></ul></li><li>心跳机制<ul><li>NataNode定期从DataNode接受心跳信息和块报告。</li><li>NameNode根据块报告验证元数据。</li><li>没有按时发送心跳的DataNode会被标记为宕机，不会再给他任何i/o请求。</li><li>如果DataNode失效造成副本数量下降，并且低于预先设置的值，NameNode会检测这些数据库，并在合适的时间重新复制。</li><li>引发重新复制的原因还包括数据副本本身损坏，磁盘错误，复制因子被增大等。</li></ul></li><li>安全模式<ul><li>NameNode启动时会经过一个“安全模式”阶段。</li><li>安全模式阶段不会产生数据写。</li><li>在此阶段NameNode收集各个DataNode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的。</li><li>在一定比例(可设置)的数据块被确定为“安全”后，再过若干时间，安全模式结束。</li><li>当检测到副本不足数据块时，该块会被复制，直到达到最小副本数。</li></ul></li><li>检验和<ul><li>在文件创立时，每个块都产生校验和。</li><li>校验和会作为单独一个隐藏文件保存在命名空间下。</li><li>客户端获取数据时可以检查校验和是否相同，从而发现数据块是否损坏。</li><li>如果正在读取的数据块损坏，则可以继续读取其他副本。</li></ul></li><li>回收站<ul><li>删除文件时，其实是放入回收站/trach中。</li><li>回收站里的文件是可以快速恢复的。</li><li>可以设置一个时间值，当回收站里的文件的存放时间超过这个值，就被彻底删除，并且释放占用的数据块。</li></ul></li><li>元数据保护<ul><li>映像文件和事务日志是NameNode的核心数据，可以配置为拥有多个副本。</li><li>副本会降低NameNode的处理速度，但增加安全性。</li><li>NameNode依然是单点，如果发生故障需要切换。</li></ul></li><li>快照机制</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-02 环境搭建</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-02%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="Hadoop-环境搭建"><a href="#Hadoop-环境搭建" class="headerlink" title="Hadoop 环境搭建"></a>Hadoop 环境搭建</h2><ol><li><p>安装jdk</p></li><li><p>安装ssh 设置免密登录</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arcade">ssh-keygen -t rsa<br>cp ~<span class="hljs-regexp">/.ssh/i</span>d_rsa_.pub ~<span class="hljs-regexp">/.ssh/</span>authorized_keys<br></code></pre></td></tr></table></figure></li><li><p>Hadoop 环境安装</p><p><code>/etc/hadoop/hadoop-env.sh</code> 修改<code>java_home</code><br>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><ul><li>3.1  <code>core-site.xml</code><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-params">&lt;configuration&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>fs.defaultFS<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span>hdfs:<span class="hljs-comment">//172.16.100.151:8020&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>hadoop.tmp.dir<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/home/</span>hadoop<span class="hljs-meta-keyword">/app/</span>tmp<span class="hljs-params">&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br><span class="hljs-params">&lt;/configuration&gt;</span><br></code></pre></td></tr></table></figure></li><li>3.2 <code>hdfs-site.xml</code><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!--副本个数--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><code>解决安全模式问题</code> “hadoop Cannot create directory Name node is in safe mode.”</li></ul></li></ol><p>离开安全模式方法：<code>bin/hadoop dfsadmin -safemode leave</code></p><h3 id="yarn-环境搭建："><a href="#yarn-环境搭建：" class="headerlink" title="yarn 环境搭建："></a>yarn 环境搭建：</h3><ol><li><p><code>etc/hadoop/mapred-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><p><code>etc/hadoop/yarn-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>     <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>         <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><p>服务启动：</p></li></ol><p><code>sbin/start-yarn.sh</code></p><p>服务停止：</p><p><code>sbin/stop-yarn.sh</code></p><p>ResourceManager - <a href="http://localhost:8088/">http://localhost:8088/</a></p>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop-01 初识Hadoop</title>
    <link href="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01%20%E5%88%9D%E8%AF%86Hadoop/"/>
    <url>/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01%20%E5%88%9D%E8%AF%86Hadoop/</url>
    
    <content type="html"><![CDATA[<h2 id="初识Hadoop"><a href="#初识Hadoop" class="headerlink" title="初识Hadoop"></a>初识Hadoop</h2><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点特别适合写一次，读多次的场景。</p><p>适合</p><ul><li>大规模数据</li><li>流式数据（写一次，读多次）</li><li>商用硬件（一般硬件）</li></ul><p>不适合</p><ul><li>低延时的数据访问</li><li>大量的小文件</li><li>频繁修改文件（基本就是写1次）<h2 id="Hadoop架构"><a href="#Hadoop架构" class="headerlink" title="Hadoop架构"></a>Hadoop架构</h2><img src="/blog/2020/11/06/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/Hadoop/Hadoop-01%20%E5%88%9D%E8%AF%86Hadoop/hadoop%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class title="hadoop架构图"></li><li>分布式文件系统hdfs</li><li>分布式资源调度yarn</li><li>分布式计算框架MapReduce</li><li>Others: 利用YARN的资源管理功能实现其他的数据处理方式</li></ul><p>hadoop包含的模块：</p><ul><li>hadoop common  – 公共模块</li><li>hadoop distributed file system（hdfs）–提供数据存储</li><li>Hadoop yarn – 作业调度，资源管理</li><li>hadoop MapReduce –yarn之上并行处理框架</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
      <category>大数据</category>
      
      <category>Hadoop</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具方法</tag>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
